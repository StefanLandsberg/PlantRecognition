import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.keras import layers, models, mixed_precision
from tensorflow.keras.applications import MobileNetV3Large
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.optimizers.schedules import CosineDecay
import os
import json
import time
import signal
import threading
import numpy as np
from tqdm.auto import tqdm
import logging
from datetime import datetime, timedelta
import sys
import glob
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import psutil
import pickle
import gc
import types
import multiprocessing
from concurrent.futures import ThreadPoolExecutor
import concurrent.futures
import shutil
import traceback
import colorama
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import StandardScaler
import os

# Define TermColors before using it
class TermColors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# Define memory limit function first thing after imports
def limit_memory_usage(gpu_memory_limit_mb=2048, ram_percent_limit=75):
    """Limit both GPU and RAM memory usage to prevent crashes
    
    Args:
        gpu_memory_limit_mb: GPU memory limit in megabytes (default: 2GB)
        ram_percent_limit: Maximum RAM usage allowed as percentage (default: 75%)
    """
    print(f"{TermColors.YELLOW}‚ö†Ô∏è MEMORY LIMITER ACTIVE{TermColors.ENDC}")
    
    # 1. GPU Memory Limiting
    physical_devices = tf.config.list_physical_devices('GPU')
    if physical_devices:
        try:
            # Set memory limit on each GPU
            for device in physical_devices:
                tf.config.set_logical_device_configuration(
                    device,
                    [tf.config.LogicalDeviceConfiguration(memory_limit=gpu_memory_limit_mb)]
                )
            print(f"{TermColors.GREEN}‚úÖ GPU memory limited to {gpu_memory_limit_mb}MB{TermColors.ENDC}")
        except Exception as e:
            print(f"{TermColors.RED}‚ùå Error setting GPU memory limit: {e}{TermColors.ENDC}")
    else:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è No GPU devices found to apply memory limit{TermColors.ENDC}")
    
    # 2. RAM Memory Monitoring Thread
    def ram_monitor_thread(ram_limit=ram_percent_limit):
        """Background thread to monitor RAM usage and prevent crashes"""
        print(f"{TermColors.GREEN}‚úÖ RAM monitor started (limit: {ram_limit}%){TermColors.ENDC}")
        while True:
            try:
                # Check current RAM usage
                mem = psutil.virtual_memory()
                if mem.percent > ram_limit:
                    print(f"{TermColors.RED}‚ö†Ô∏è RAM usage critical: {mem.percent}% > {ram_limit}%{TermColors.ENDC}")
                    print(f"{TermColors.YELLOW}‚è∏Ô∏è Force releasing memory...{TermColors.ENDC}")
                        
                    # Force garbage collection
                    gc.collect()
                        
                    # Try to release large objects
                    for obj in gc.get_objects():
                        try:
                            if isinstance(obj, (np.ndarray, tf.Tensor)):
                                if hasattr(obj, 'nbytes') and getattr(obj, 'nbytes', 0) > 1e6:
                                    del obj
                        except Exception:
                            pass
                        
                    # For extreme cases, try to reduce TensorFlow memory
                    if mem.percent > ram_limit + 10:
                        print(f"{TermColors.RED}üö® CRITICAL RAM USAGE: {mem.percent}%{TermColors.ENDC}")
                        tf.keras.backend.clear_session()
                        # Sleep to allow system to recover
                        time.sleep(5)
                            
                # Check less frequently when RAM usage is normal    
                time.sleep(5 if mem.percent > ram_limit - 10 else 30)
                    
            except Exception as e:
                # Don't let monitoring thread crash
                print(f"{TermColors.RED}‚ùå RAM monitor error: {e}{TermColors.ENDC}")
                time.sleep(60)
    
    # Start RAM monitor in background
    try:
        ram_thread = threading.Thread(target=ram_monitor_thread, args=(ram_percent_limit,), daemon=True)
        ram_thread.start()
    except Exception as e:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Could not start RAM monitor: {e}{TermColors.ENDC}")

# Apply memory limits immediately
limit_memory_usage(6144, 75)  # Using 6GB of GPU memory and 75% RAM threshold

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0=all, 1=no INFO, 2=no WARNING, 3=no ERROR
tf.get_logger().setLevel('ERROR')

print(f"\n{TermColors.GREEN}‚úÖ TensorFlow is using GPU: {tf.test.is_gpu_available()}{TermColors.ENDC}")

# Force TensorFlow to see and use the GPU correctly
print("TensorFlow version:", tf.__version__)
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# Force device placement logging
tf.debugging.set_log_device_placement(False)

# Configure TensorFlow to use the GPU 
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    print("GPU is available:", physical_devices)
    try:
        # Only allow TensorFlow to see the first GPU
        tf.config.set_visible_devices(physical_devices[0], 'GPU')
        logical_devices = tf.config.list_logical_devices('GPU')
        print("Logical GPU devices:", logical_devices)
        print("Successfully configured GPU")
    except RuntimeError as e:
        print("GPU configuration error:", e)
else:
    print("‚ö†Ô∏è WARNING: No GPU found. Running on CPU only!")

# Initialize colorama for cross-platform colored terminal output
colorama.init()

# Configuration
DATA_DIR = r"C:\Users\stefa\Desktop\New folder\data\completed_images"
FEATURES_DIR = r"C:\Users\stefa\Desktop\New folder\data\features"
MODEL_DIR = r"C:\Users\stefa\Desktop\New folder\models"
CHECKPOINT_DIR = r"C:\Users\stefa\Desktop\New folder\checkpoints"
LOG_DIR = r"C:\Users\stefa\Desktop\New folder\logs"
STATS_DIR = r"C:\Users\stefa\Desktop\New folder\stats"

# Training Parameters
BATCH_SIZE = 32
IMAGE_SIZE = (224, 224)
EPOCHS = 50
MAX_CLASSES_PER_CHUNK = 1000
TOP_K = 10
INITIAL_LR = 1e-3
CPU_WORKERS = min(6, multiprocessing.cpu_count() - 1)  # Leave one core free
GRADIENT_ACCUMULATION_STEPS = 4
MEMORY_CLEANUP_FREQ = 500

# Create required directories
for directory in [FEATURES_DIR, MODEL_DIR, CHECKPOINT_DIR, LOG_DIR, STATS_DIR]:
    os.makedirs(directory, exist_ok=True)

# Enable mixed precision for better GPU performance
mixed_precision.set_global_policy('float32')

# Metrics formatting
def format_metrics(metrics_dict):
    """Format metrics dictionary into colored string"""
    formatted = []
    for key, value in metrics_dict.items():
        if isinstance(value, str):
            # Handle string values
            formatted.append(f"{key}: {value}")
        elif 'accuracy' in key:
            color = TermColors.GREEN
            formatted.append(f"{color}{key}: {value:.4f}{TermColors.ENDC}")
        elif 'loss' in key:
            color = TermColors.RED
            formatted.append(f"{color}{key}: {value:.4f}{TermColors.ENDC}")
        else:
            formatted.append(f"{key}: {value:.4f}")
    return " | ".join(formatted)

# Custom tqdm for showing metrics
class MetricsTQDM(tqdm):
    """Custom tqdm progress bar that displays training metrics"""
    def __init__(self, *args, **kwargs):
        # Initialize metrics and flag before super().__init__
        self.metrics = {}
        self._metrics_updated = False
        # Now call the parent constructor
        super().__init__(*args, **kwargs)
        
    def update_metrics(self, epoch, metrics):
        """Update training metrics in history"""
        self.current_epoch = epoch
        for key, value in metrics.items():
            if key not in self.history:
                self.history[key] = []
            # Ensure we don't have more entries than epochs
            while len(self.history[key]) <= epoch:
                self.history[key].append(None)
            
            # Handle non-numeric types properly
            try:
                # Try to convert to float
                self.history[key][epoch] = float(value)
            except (ValueError, TypeError):
                # If conversion fails, store as string representation
                self.history[key][epoch] = str(value)
        
        # Update best metrics
        val_loss = metrics.get('val_loss')
        val_accuracy = metrics.get('val_accuracy')
        
        if val_loss is not None and isinstance(val_loss, (float, int)):
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.epochs_without_improvement = 0
            else:
                self.epochs_without_improvement += 1
        
        if val_accuracy is not None and isinstance(val_accuracy, (float, int)):
            if val_accuracy > self.best_val_accuracy:
                self.best_val_accuracy = val_accuracy
        
        self.save_state()
        
    def display(self, msg=None, pos=None):
        """Override display to include metrics"""
        # We don't need special handling anymore - postfix is set directly in update_metrics
        return super().display(msg, pos)

# Training state management
class TrainingState:
    """Manages training state for pause/resume functionality"""
    def __init__(self, state_file=os.path.join(CHECKPOINT_DIR, "training_state.json")):
        self.state_file = state_file
        self.current_chunk = 0
        self.current_epoch = 0
        self.processed_chunks = []
        self.history = {}
        self.best_val_loss = float('inf')
        self.best_val_accuracy = 0
        self.epochs_without_improvement = 0
        self.load_state()
    
    def load_state(self):
        """Load saved training state if exists"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
                    self.current_chunk = state.get('current_chunk', 0)
                    self.current_epoch = state.get('current_epoch', 0)
                    self.processed_chunks = state.get('processed_chunks', [])
                    self.history = state.get('history', {})
                    self.best_val_loss = state.get('best_val_loss', float('inf'))
                    self.best_val_accuracy = state.get('best_val_accuracy', 0)
                print(f"{TermColors.GREEN}‚úÖ Resuming from chunk {self.current_chunk}, epoch {self.current_epoch}{TermColors.ENDC}")
            except Exception as e:
                print(f"{TermColors.YELLOW}‚ö†Ô∏è Could not load training state: {e}{TermColors.ENDC}")
    
    def save_state(self):
        """Save current training state"""
        state = {
            'current_chunk': self.current_chunk,
            'current_epoch': self.current_epoch,
            'processed_chunks': self.processed_chunks,
            'history': self.history,
            'best_val_loss': self.best_val_loss,
            'best_val_accuracy': self.best_val_accuracy,
            'last_updated': datetime.now().isoformat()
        }
        with open(self.state_file, 'w') as f:
            json.dump(state, f, indent=2)
    
    def update_metrics(self, epoch, metrics):
        """Update training metrics in history"""
        self.current_epoch = epoch
        for key, value in metrics.items():
            if key not in self.history:
                self.history[key] = []
            # Ensure we don't have more entries than epochs
            while len(self.history[key]) <= epoch:
                self.history[key].append(None)
            self.history[key][epoch] = float(value)
        
        # Update best metrics
        val_loss = metrics.get('val_loss')
        val_accuracy = metrics.get('val_accuracy')
        
        if val_loss is not None and val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.epochs_without_improvement = 0
        else:
            self.epochs_without_improvement += 1
        
        if val_accuracy is not None and val_accuracy > self.best_val_accuracy:
            self.best_val_accuracy = val_accuracy
        
        self.save_state()
    
    def mark_chunk_complete(self, chunk_idx):
        """Mark a chunk as completely processed"""
        if chunk_idx not in self.processed_chunks:
            self.processed_chunks.append(chunk_idx)
        self.current_chunk = chunk_idx + 1
        self.current_epoch = 0
        self.best_val_loss = float('inf')
        self.best_val_accuracy = 0
        self.epochs_without_improvement = 0
        self.history = {}
        self.save_state()

def load_and_preprocess_image(img_path):
    """Load and preprocess a single image file"""
    try:
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
        img = tf.keras.preprocessing.image.img_to_array(img)
        img = img / 255.0
        return img
    except Exception:
        return None

def preprocess_image_enhanced(img_path):
    """Enhanced preprocessing with advanced augmentation"""
    try:
        # Load image
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        
        # Create multiple augmented versions
        augmented_images = []
        
        # Original image with proper preprocessing
        img_orig = tf.keras.applications.convnext.preprocess_input(img_array.copy())
        augmented_images.append(img_orig)
        
        # Slight rotation (common in plant photos)
        img_rot = tf.keras.preprocessing.image.apply_affine_transform(
            img_array.copy(), theta=np.random.uniform(-20, 20))
        img_rot = tf.keras.applications.convnext.preprocess_input(img_rot)
        augmented_images.append(img_rot)
        
        # Slight zoom (simulate different distances)
        img_zoom = tf.keras.preprocessing.image.apply_affine_transform(
            img_array.copy(), zx=np.random.uniform(0.8, 1.2), zy=np.random.uniform(0.8, 1.2))
        img_zoom = tf.keras.applications.convnext.preprocess_input(img_zoom)
        augmented_images.append(img_zoom)
        
        # Changes in brightness/contrast
        img_bright = img_array.copy() * np.random.uniform(0.8, 1.2)
        img_bright = np.clip(img_bright, 0, 255)
        img_bright = tf.keras.applications.convnext.preprocess_input(img_bright)
        augmented_images.append(img_bright)
        
        # Random crop with padding
        img_crop = tf.keras.preprocessing.image.apply_affine_transform(
            img_array.copy(), zx=0.8, zy=0.8)
        img_crop = tf.keras.applications.convnext.preprocess_input(img_crop)
        augmented_images.append(img_crop)
        
        return augmented_images
    except Exception as e:
        print(f"Error processing {img_path}: {e}")
        return None

# Define metrics functions
def sparse_top_k_accuracy(y_true, y_pred):
    """Calculate top-K accuracy for sparse labels"""
    return tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=TOP_K)

# Custom callbacks
class MetricsDisplayCallback(tf.keras.callbacks.Callback):
    """Display metrics during training with progress bars"""
    def __init__(self, total_epochs, validation_data=None, training_state=None):
        super().__init__()
        self.epoch_bar = None
        self.batch_bar = None
        self.total_epochs = total_epochs
        self.training_state = training_state
        self.validation_data = validation_data
        self.start_time = None
        self.epoch_times = []
        self.current_metrics = {}
        self.stop_flag = False
        
        # Setup signal handler for graceful stopping
        self.original_sigint = signal.getsignal(signal.SIGINT)
        signal.signal(signal.SIGINT, self._signal_handler)
        
    def _signal_handler(self, sig, frame):
        """Handle Ctrl+C signal gracefully"""
        print(f"\n{TermColors.YELLOW}‚è∏Ô∏è Training pause requested (Ctrl+C). Will stop after current batch.{TermColors.ENDC}")
        self.stop_flag = True
        self.model.stop_training = True
    
    def check_keyboard_shortcut(self):
        """Check if Ctrl+Alt+C is pressed to stop training gracefully"""
        try:
            # Check if keyboard module is imported, if not, import it
            try:
                import keyboard
            except ImportError:
                print(f"{TermColors.YELLOW}‚ö†Ô∏è Keyboard module not found. Installing...{TermColors.ENDC}")
                import subprocess
                subprocess.check_call([sys.executable, "-m", "pip", "install", "keyboard"])
                import keyboard
                
            if keyboard.is_pressed('ctrl+alt+c'):
                print(f"\n{TermColors.YELLOW}‚è∏Ô∏è Training pause requested (Ctrl+Alt+C). Will stop after current batch.{TermColors.ENDC}")
                self.stop_flag = True
                self.model.stop_training = True
                return True
            return False
        except Exception as e:
            # If keyboard monitoring fails, silently continue
            return False
    
    def on_train_begin(self, logs=None):
        self.start_time = time.time()
        print(f"{TermColors.HEADER}\n{'='*50}")
        print(f"BEGINNING MODEL TRAINING")
        print(f"{'='*50}{TermColors.ENDC}")
        print(f"{TermColors.CYAN}‚Ñπ Press Ctrl+Alt+C to stop training gracefully{TermColors.ENDC}")
        
        # Create epoch progress bar
        self.epoch_bar = tqdm(
            total=self.total_epochs, 
            desc="Epochs", 
            position=0, 
            leave=True,
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
        )
        
        # Update to starting epoch if resuming
        if self.training_state and self.training_state.current_epoch > 0:
            self.epoch_bar.update(self.training_state.current_epoch)
    
    def on_train_end(self, logs=None):
        self.stop_flag = True
        
        if self.epoch_bar:
            self.epoch_bar.close()
        if self.batch_bar:
            self.batch_bar.close()
        
        # Calculate and print training summary
        total_time = time.time() - self.start_time
        hours, remainder = divmod(total_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        print(f"\n{TermColors.HEADER}{'='*50}")
        print(f"TRAINING COMPLETE")
        print(f"{'='*50}")
        print(f"Total training time: {int(hours)}h {int(minutes)}m {int(seconds)}s")
        print(f"Final metrics: {format_metrics(logs or {})}")
        print(f"{'='*50}{TermColors.ENDC}")
    
    def on_epoch_begin(self, epoch, logs=None):
        self.current_epoch_start = time.time()
        self.current_epoch = epoch
    
    # Use standard tqdm instead of MetricsTQDM
        self.batch_bar = tqdm(
            desc=f"Batch (Epoch {epoch+1}/{self.total_epochs})",
            total=self.params['steps'],
            position=1, 
            leave=False,
            unit='batch',
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'
        )
    
    def on_epoch_end(self, epoch, logs=None):
        """Update epoch progress bar and save metrics at the end of each epoch"""
        # Update epoch progress bar with metrics
        if self.epoch_bar:
            self.epoch_bar.update(1)
        
        # Calculate epoch time
        epoch_time = time.time() - self.current_epoch_start
        self.epoch_times.append(epoch_time)
        
        # Estimate remaining time
        if len(self.epoch_times) > 0:
            avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)
            remaining_epochs = self.total_epochs - (epoch + 1)
            eta_seconds = avg_epoch_time * remaining_epochs
            eta = str(timedelta(seconds=int(eta_seconds)))
            
            # Enhanced metrics display with better type handling
            metrics_display = []
            
            # Always show these metrics in this order if available
            priority_metrics = ['loss', 'val_loss', 'accuracy', 'val_accuracy', 'sparse_top_k_accuracy', 'val_sparse_top_k_accuracy']
            
            for metric in priority_metrics:
                if metric in logs:
                    value = logs[metric]
                    # Check if value is a formatting-compatible type
                    if isinstance(value, (float, int, np.float32, np.float64, np.int32, np.int64)):
                        if 'loss' in metric:
                            color = TermColors.RED
                            metrics_display.append(f"{color}{metric}: {value:.4f}{TermColors.ENDC}")
                        elif 'accuracy' in metric:
                            color = TermColors.GREEN
                            metrics_display.append(f"{color}{metric}: {value:.4f}{TermColors.ENDC}")
                        else:
                            metrics_display.append(f"{metric}: {value:.4f}")
                    else:
                        # Handle non-numeric types like CosineDecay
                        metrics_display.append(f"{metric}: {str(value)}")
            
            # Add any remaining metrics with type checking
            for metric, value in logs.items():
                if metric not in priority_metrics:
                    if isinstance(value, (float, int, np.float32, np.float64, np.int32, np.int64)):
                        metrics_display.append(f"{metric}: {value:.4f}")
                    else:
                        metrics_display.append(f"{metric}: {str(value)}")
            
            metrics_str = " | ".join(metrics_display)
            self.epoch_bar.set_postfix_str(f"ETA: {eta} | {metrics_str}")
        
        # Close batch progress bar
        if self.batch_bar:
            self.batch_bar.close()
            self.batch_bar = None
        
        # Save metrics in training state
        if self.training_state and logs:
            # Create a copy of logs with only serializable values
            filtered_logs = {}
            for key, value in (logs or {}).items():
                # Remove learning rate schedule objects that can't be serialized
                if key == 'lr' and not isinstance(value, (float, int, np.float32, np.float64)):
                    # Try to extract current lr value if possible
                    try:
                        if hasattr(value, '__call__'):
                            step = self.model.optimizer.iterations.numpy()
                            filtered_logs[key] = float(value(step).numpy())
                        else:
                            filtered_logs[key] = str(value)
                    except:
                        filtered_logs[key] = f"<schedule>"
                elif isinstance(value, (float, int, np.float32, np.float64, np.int32, np.int64)):
                    filtered_logs[key] = float(value)
                else:
                    filtered_logs[key] = str(value)
                    
            self.training_state.update_metrics(epoch, filtered_logs)
    
    def on_batch_end(self, batch, logs=None):
        if self.batch_bar:
            self.batch_bar.update(1)
        
        # Only update metrics display periodically to reduce overhead
        if batch % 10 == 0 and logs:
            # Format metrics string directly
            metrics_str = ""
            for k, v in logs.items():
                if isinstance(v, str):
                    metrics_str += f" | {k}: {v}"
                elif 'loss' in k:
                    metrics_str += f" | {TermColors.RED}{k}: {v:.4f}{TermColors.ENDC}"
                elif 'accuracy' in k:
                    metrics_str += f" | {TermColors.GREEN}{k}: {v:.4f}{TermColors.ENDC}"
                else:
                    metrics_str += f" | {k}: {v:.4f}"
                    
            # Update the description instead of using custom metrics display
            self.batch_bar.set_description(
                f"Batch (Epoch {self.current_epoch+1}/{self.total_epochs}){metrics_str}"
            )
            
            # Check for keyboard shortcut
            if batch % 10 == 0:
                self.check_keyboard_shortcut()
    
    # Check for stop flag
        if self.stop_flag:
            self.model.stop_training = True

class AutoTrainingConfig(tf.keras.callbacks.Callback):
    """Automatically adjust training parameters based on performance"""
    def __init__(self, initial_lr=INITIAL_LR, training_state=None):
        super().__init__()
        self.initial_lr = initial_lr
        self.training_state = training_state
        self.plateau_count = 0
        self.best_val_loss = float('inf')
    
    def on_epoch_end(self, epoch, logs=None):
        if not logs or 'val_loss' not in logs:
            return
            
        val_loss = logs['val_loss']
        
        # Fixed: Handle CosineDecay learning rate correctly
        try:
            if hasattr(self.model.optimizer.lr, '__call__'):
                # For LearningRateSchedule objects like CosineDecay
                current_step = self.model.optimizer.iterations.numpy()
                current_lr = self.model.optimizer.lr(current_step).numpy()
            else:
                # For fixed learning rates
                current_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))
        except:
            # Fallback if we can't get the learning rate
            current_lr = 0.001
        
        # Check if validation loss improved
        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.plateau_count = 0
            print(f"{TermColors.GREEN}‚úì Validation loss improved to {val_loss:.4f}{TermColors.ENDC}")
        else:
            self.plateau_count += 1
            print(f"{TermColors.YELLOW}‚ö† Validation loss plateau: {self.plateau_count} epochs without improvement{TermColors.ENDC}")
            
            # If we have a plateau for too long, adjust learning rate
            if self.plateau_count >= 3:
                new_lr = current_lr * 0.5
                if new_lr < 1e-6:  # Don't go too low
                    new_lr = 1e-6
                
                print(f"{TermColors.YELLOW}‚öô Reducing learning rate: {current_lr:.6f} ‚Üí {new_lr:.6f}{TermColors.ENDC}")
                # Set the new learning rate safely
                try:
                    tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                except:
                    print(f"{TermColors.YELLOW}‚ö† Could not update learning rate - using schedule instead{TermColors.ENDC}")
                self.plateau_count = 0  # Reset counter after adjustment

# Advanced training configuration with gradual unfreezing
def create_custom_callbacks():
    class GradualUnfreezingCallback(tf.keras.callbacks.Callback):
        def __init__(self, model, feature_dim):
            super().__init__()
            self.model = model
            self.feature_dim = feature_dim
            self.unfrozen_layers = 0
            
        def on_epoch_end(self, epoch, logs=None):
            # Every 5 epochs, make the model slightly more complex
            if epoch > 0 and epoch % 5 == 0 and self.unfrozen_layers < 3:
                if self.unfrozen_layers == 0:
                    # Add a new layer
                    x = self.model.layers[-2].output
                    new_layer = layers.Dense(512, activation='swish')(x)
                    outputs = layers.Dense(self.model.output.shape[1], activation='softmax')(new_layer)
                    new_model = tf.keras.Model(inputs=self.model.input, outputs=outputs)
                    weights = self.model.get_weights()
                    self.model = new_model
                    self.model.compile(optimizer=self.model.optimizer, 
                                     loss='sparse_categorical_crossentropy',
                                     metrics=['accuracy', sparse_top_k_accuracy])
                    print(f"{TermColors.CYAN}‚ú® Added complexity at epoch {epoch+1}{TermColors.ENDC}")
                    
                self.unfrozen_layers += 1
    
    return [GradualUnfreezingCallback(model, feature_dim)]  # Add to your callbacks list

def analyze_features(features_file):
    """Analyze feature quality to detect problems"""
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"FEATURE QUALITY ANALYSIS")
    print(f"{'='*50}{TermColors.ENDC}")
    
    features, labels = load_features(features_file)
    
    # Check for NaN values
    nan_count = np.isnan(features).sum()
    if nan_count > 0:
        print(f"{TermColors.RED}‚ùå Found {nan_count} NaN values in features!{TermColors.ENDC}")
    
    # Check feature variance
    feature_variance = np.var(features, axis=0)
    low_variance = (feature_variance < 1e-5).sum()
    if low_variance > features.shape[1] // 2:
        print(f"{TermColors.RED}‚ùå {low_variance}/{features.shape[1]} features have very low variance!{TermColors.ENDC}")
    
    # Check for uniform distribution (indicates potential preprocessing issue)
    feature_ranges = np.ptp(features, axis=0)
    if np.mean(feature_ranges) < 0.1:
        print(f"{TermColors.RED}‚ùå Features have very small range (mean range: {np.mean(feature_ranges):.6f}){TermColors.ENDC}")
    
    # Check for class separability
    from sklearn.decomposition import PCA
    from sklearn.metrics import silhouette_score
    
    print(f"{TermColors.CYAN}‚Ñπ Analyzing class separability...{TermColors.ENDC}")
    
    # Use PCA to reduce dimensions 
    pca = PCA(n_components=min(100, features.shape[0]//10, features.shape[1]))
    reduced_features = pca.fit_transform(features)
    
    # Sample for silhouette score (max 10,000 samples)
    if len(features) > 10000:
        indices = np.random.choice(len(features), 10000, replace=False)
        sample_features = reduced_features[indices]
        sample_labels = labels[indices]
    else:
        sample_features = reduced_features
        sample_labels = labels
    
    try:
        silhouette = silhouette_score(sample_features, sample_labels)
        print(f"{TermColors.CYAN}‚Ñπ Class separability (silhouette score): {silhouette:.4f}{TermColors.ENDC}")
        
        if silhouette < 0.1:
            print(f"{TermColors.RED}‚ùå Poor class separability in features!{TermColors.ENDC}")
        elif silhouette < 0.3:
            print(f"{TermColors.YELLOW}‚ö†Ô∏è Mediocre class separability in features{TermColors.ENDC}")
        else:
            print(f"{TermColors.GREEN}‚úÖ Good class separability in features{TermColors.ENDC}")
    except:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Unable to calculate class separability{TermColors.ENDC}")
    
    # Check explained variance from PCA
    explained_variance = np.sum(pca.explained_variance_ratio_)
    print(f"{TermColors.CYAN}‚Ñπ Top 100 components explain {explained_variance:.2%} of variance{TermColors.ENDC}")
    
    if explained_variance < 0.5:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Features have high dimensionality with limited structure{TermColors.ENDC}")
    
    return features, labels

def analyze_plant_features(features, labels):
    """Specialized analysis for plant feature quality"""
    # Calculate inter-class similarity matrix
    from sklearn.metrics.pairwise import cosine_similarity
    
    # Sample for performance if needed
    if len(features) > 5000:
        indices = np.random.choice(len(features), 5000, replace=False)
        sample_features = features[indices]
        sample_labels = labels[indices]
    else:
        sample_features = features
        sample_labels = labels
    
    # Get unique classes
    unique_classes = np.unique(sample_labels)
    
    # Calculate class centroids
    centroids = []
    for cls in unique_classes:
        class_features = sample_features[sample_labels == cls]
        centroid = np.mean(class_features, axis=0)
        centroids.append(centroid)
    
    centroids = np.array(centroids)
    
    # Calculate similarity between class centroids
    similarity = cosine_similarity(centroids)
    np.fill_diagonal(similarity, 0)  # Remove self-similarity
    
    # Analyze potential confusion points
    high_similarity = np.where(similarity > 0.9)
    confusion_pairs = list(zip(high_similarity[0], high_similarity[1]))
    
    if confusion_pairs:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Found {len(confusion_pairs)} potentially confusable class pairs{TermColors.ENDC}")
        # Print a few examples
        for i, j in confusion_pairs[:5]:
            print(f"  - Classes {unique_classes[i]} and {unique_classes[j]}: {similarity[i,j]:.4f} similarity")
    else:
        print(f"{TermColors.GREEN}‚úÖ No highly confusable classes detected{TermColors.ENDC}")
    
    # Return confusability score (lower is better)
    return np.mean(similarity)

def analyze_model_performance():
    """Analyze all chunk models and identify low-performing ones"""
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"ANALYZING CHUNK MODEL PERFORMANCE")
    print(f"{'='*50}{TermColors.ENDC}")
    
    model_files = glob.glob(os.path.join(MODEL_DIR, "chunk_*_metadata.json"))
    
    if not model_files:
        print(f"{TermColors.RED}‚ùå No model metadata files found{TermColors.ENDC}")
        return
        
    print(f"{TermColors.CYAN}‚Ñπ Found {len(model_files)} trained chunks{TermColors.ENDC}")
    
    # Track performance metrics
    all_performance = []
    problematic_chunks = []
    
    for metadata_file in model_files:
        chunk_idx = int(os.path.basename(metadata_file).split("_")[1])
        
        with open(metadata_file) as f:
            metadata = json.load(f)
            
        # Get performance metrics
        val_acc = metadata.get('performance', {}).get('val_accuracy', 0.0)
        val_top_k = metadata.get('performance', {}).get('val_sparse_top_k_accuracy', 0.0)
        num_classes = metadata.get('num_classes', 0)
        
        all_performance.append((chunk_idx, val_acc, val_top_k, num_classes))
        
        # Flag chunks with accuracy below threshold
        if val_acc < 0.6:  # 60% threshold
            problematic_chunks.append((chunk_idx, val_acc, val_top_k, num_classes))
    
    # Sort by accuracy
    all_performance.sort(key=lambda x: x[1])
    
    # Display overall statistics
    avg_acc = sum(p[1] for p in all_performance) / len(all_performance) if all_performance else 0
    avg_top_k = sum(p[2] for p in all_performance) / len(all_performance) if all_performance else 0
    
    print(f"\n{TermColors.CYAN}üìä OVERALL PERFORMANCE:{TermColors.ENDC}")
    print(f"Average accuracy: {avg_acc:.2%}")
    print(f"Average top-{TOP_K} accuracy: {avg_top_k:.2%}")
    
    # Display worst performing chunks
    print(f"\n{TermColors.YELLOW}‚ö†Ô∏è LOWEST PERFORMING CHUNKS:{TermColors.ENDC}")
    for i, (chunk_idx, acc, top_k, num_classes) in enumerate(all_performance[:5]):
        print(f"{i+1}. Chunk {chunk_idx}: Accuracy {acc:.2%}, Top-{TOP_K} {top_k:.2%} ({num_classes} classes)")
    
    # Display problematic chunks
    if problematic_chunks:
        print(f"\n{TermColors.RED}‚ùå PROBLEMATIC CHUNKS (Below 60% accuracy):{TermColors.ENDC}")
        for chunk_idx, acc, top_k, num_classes in problematic_chunks:
            print(f"Chunk {chunk_idx}: Accuracy {acc:.2%}, Top-{TOP_K} {top_k:.2%} ({num_classes} classes)")
        
        print(f"\n{TermColors.CYAN}‚ÑπÔ∏è To retrain problematic chunks, run:{TermColors.ENDC}")
        print(f"retrain_chunk([{', '.join(str(c[0]) for c in problematic_chunks)}])")
    else:
        print(f"\n{TermColors.GREEN}‚úÖ No problematic chunks detected!{TermColors.ENDC}")
        
    return problematic_chunks

def scan_class_directory(args):
        class_idx, class_dir = args
        class_name = os.path.basename(class_dir)
        paths = []
        indices = []
        
        for img_name in os.listdir(class_dir):
            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(class_dir, img_name)
                paths.append(img_path)
                indices.append(class_idx)
                
        return class_name, paths, indices

def extract_enhanced_features(class_dirs, chunk_idx):
    """Enhanced feature extraction using EfficientNetV2L with optimized resource utilization"""
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"HIGH-PERFORMANCE FEATURE EXTRACTION FOR CHUNK {chunk_idx+1}")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Setup keyboard interrupt checking
    stop_requested = False
    last_keyboard_check = time.time()
    
    def check_keyboard_interrupt():
        nonlocal stop_requested, last_keyboard_check
        current_time = time.time()
        if current_time - last_keyboard_check < 1.0:
            return stop_requested
        last_keyboard_check = current_time
        try:
            import keyboard
            if keyboard.is_pressed('ctrl+alt+c'):
                print(f"\n{TermColors.YELLOW}‚è∏Ô∏è Feature extraction pause requested (Ctrl+Alt+C). Will stop after current batch.{TermColors.ENDC}")
                stop_requested = True
                return True
        except Exception:
            pass
        return stop_requested

    # Use EfficientNetV2L with optimized settings
    with tf.device('/GPU:0'):
        # Use smaller model for faster processing while maintaining quality
        from tensorflow.keras.applications import EfficientNetV2L
        
        base_model = EfficientNetV2L(
            input_shape=(*IMAGE_SIZE, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        base_model.trainable = False
        feature_extractor = tf.keras.Model(inputs=base_model.input, outputs=base_model.output)
    
    feature_dim = feature_extractor.output_shape[1]
    print(f"{TermColors.GREEN}‚úÖ Feature extractor loaded: EfficientNetV2L ({feature_dim} dims){TermColors.ENDC}")
    
    # Storage for features - simple approach that worked before
    all_features = []
    all_labels = []
    class_names = []
    
    # Create chunk feature directory
    chunk_feature_dir = os.path.join(FEATURES_DIR, f"chunk_{chunk_idx}")
    os.makedirs(chunk_feature_dir, exist_ok=True)
    
    # Collect all image paths with parallel processing
    print(f"{TermColors.CYAN}‚Ñπ Collecting image paths with parallel processing{TermColors.ENDC}")
    
    all_image_paths = []
    all_class_indices = []
    
    # Use process pool for truly parallel directory scanning
    with multiprocessing.Pool(processes=CPU_WORKERS) as pool:
        results = list(tqdm(
            pool.imap(scan_class_directory, enumerate(class_dirs)),
            total=len(class_dirs),
            desc="Scanning classes",
            position=0
        ))
    
    # Combine results
    for class_name, paths, indices in results:
        class_names.append(class_name)
        all_image_paths.extend(paths)
        all_class_indices.extend(indices)
    
    total_images = len(all_image_paths)
    
    if total_images == 0:
        print(f"{TermColors.RED}‚ùå No valid images found in provided class directories!{TermColors.ENDC}")
        return None, None
    
    print(f"{TermColors.GREEN}‚úÖ Found {total_images} images across {len(class_names)} classes{TermColors.ENDC}")
    
    # Process in smaller batches to reduce memory usage
    batch_size = 64  # Smaller batch size to prevent memory issues
    print(f"{TermColors.CYAN}‚Ñπ Using batch size of {batch_size} for feature extraction{TermColors.ENDC}")
    
    # Create progress bar
    progress_bar = tqdm(total=total_images, desc="Extracting features", position=0)
    
    # Process images in batches
    for i in range(0, len(all_image_paths), batch_size):
        if check_keyboard_interrupt():
            print(f"{TermColors.YELLOW}‚ö†Ô∏è Feature extraction interrupted. Saving progress...{TermColors.ENDC}")
            break
        
        batch_paths = all_image_paths[i:i+batch_size]
        batch_indices = all_class_indices[i:i+batch_size]
        
        # Load and preprocess images
        batch_images = []
        valid_indices = []
        
        for j, (img_path, class_idx) in enumerate(zip(batch_paths, batch_indices)):
            try:
                img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
                img = tf.keras.preprocessing.image.img_to_array(img)
                img = tf.keras.applications.efficientnet_v2.preprocess_input(img)
                batch_images.append(img)
                valid_indices.append(class_idx)
            except Exception as e:
                print(f"Error loading image {img_path}: {e}")
        
        # Skip if no valid images in batch
        if not batch_images:
            continue
        
        # Convert to numpy array
        batch_array = np.array(batch_images)
        
        # Extract features
        batch_features = feature_extractor.predict(batch_array, verbose=0)
        
        # Store features and labels
        for feature, class_idx in zip(batch_features, valid_indices):
            all_features.append(feature)
            all_labels.append(class_idx)
        
        # Update progress bar
        progress_bar.update(len(batch_images))
        
        # Force garbage collection periodically
        if i % (batch_size * 10) == 0:
            gc.collect()
    
    progress_bar.close()
    
    # Save class mapping
    class_mapping = {idx: name for idx, name in enumerate(class_names)}
    with open(os.path.join(chunk_feature_dir, "class_mapping.json"), "w") as f:
        json.dump(class_mapping, f, indent=2)
    
    # Convert to numpy arrays
    if len(all_features) == 0:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è No features extracted. Aborting.{TermColors.ENDC}")
        return None, None
    
    print(f"{TermColors.CYAN}‚Ñπ Saving {len(all_features)} features to disk{TermColors.ENDC}")
    features_array = np.array(all_features)
    labels_array = np.array(all_labels)
    
    # Save features to disk
    features_file = os.path.join(chunk_feature_dir, "features.npz")
    np.savez_compressed(features_file, features=features_array, labels=labels_array)
    
    print(f"{TermColors.GREEN}‚úÖ Features saved to {features_file}{TermColors.ENDC}")
    return features_file, class_mapping

def prune_features_rolling_window(current_chunk_idx, window_size=1):  # Reduced window size to 1
    """Aggressively remove feature files after model training to save disk space
    
    Args:
        current_chunk_idx: The chunk that was just processed
        window_size: Number of chunks to keep (default: 1 - only keep current chunk)
    """
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"AGGRESSIVE FEATURE MANAGEMENT")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Check all chunks up to the current one for possible deletion
    for chunk_to_check in range(current_chunk_idx + 1):  # Include current chunk in check
        # Skip the most recent chunks based on window_size
        if chunk_to_check > current_chunk_idx - window_size:
            continue
            
        # Check if this chunk's features exist
        chunk_feature_dir = os.path.join(FEATURES_DIR, f"chunk_{chunk_to_check}")
        feature_file = os.path.join(chunk_feature_dir, "features.npz")
        
        if os.path.exists(feature_file):
            # Check if model for this chunk exists (we don't want to delete features 
            # if the model doesn't exist or training failed)
            model_file = os.path.join(MODEL_DIR, f"chunk_{chunk_to_check}_model.keras")
            metadata_file = os.path.join(MODEL_DIR, f"chunk_{chunk_to_check}_metadata.json")
            
            if os.path.exists(model_file) and os.path.exists(metadata_file):
                # Get file size before deletion for reporting
                file_size_mb = os.path.getsize(feature_file) / (1024 * 1024)
                
                print(f"{TermColors.YELLOW}‚ö†Ô∏è Removing features for chunk {chunk_to_check} to save disk space ({file_size_mb:.2f} MB){TermColors.ENDC}")
                
                # Remove the feature file but keep the class mapping
                os.remove(feature_file)
                
                # Create a placeholder to indicate features were deleted
                with open(os.path.join(chunk_feature_dir, "features_pruned.txt"), "w") as f:
                    f.write(f"Features were pruned on {datetime.now().isoformat()} to save disk space.\n")
                    f.write(f"Original size: {file_size_mb:.2f} MB\n")
                    f.write(f"Model is preserved at: {model_file}\n")
                
                print(f"{TermColors.GREEN}‚úÖ Freed {file_size_mb:.2f} MB of disk space{TermColors.ENDC}")
            else:
                print(f"{TermColors.CYAN}‚Ñπ Keeping features for chunk {chunk_to_check} because model not found or incomplete{TermColors.ENDC}")

def load_features(features_file):
    """Load extracted features from file with verification to detect corruption"""
    print(f"{TermColors.CYAN}‚Ñπ Loading features from {features_file}{TermColors.ENDC}")
    
    # Add this corruption check before loading
    try:
        file_size = os.path.getsize(features_file)
        if file_size < 1000:  # Suspiciously small
            print(f"{TermColors.RED}‚ö†Ô∏è Feature file appears corrupted (only {file_size} bytes){TermColors.ENDC}")
            raise ValueError("Feature file too small, likely corrupted")
            
        # Now proceed with loading
        load_bar = tqdm(total=1, desc="Loading features")
        data = np.load(features_file)
        features = data['features']
        labels = data['labels']
        load_bar.update(1)
        load_bar.close()
        
        print(f"{TermColors.GREEN}‚úÖ Loaded {features.shape[0]} features with {features.shape[1]} dimensions{TermColors.ENDC}")
        return features, labels
        
    except Exception as e:
        print(f"{TermColors.RED}‚ùå Error loading features: {e}{TermColors.ENDC}")
        return None, None

# In your build_model function, add attention mechanism
def build_model(feature_dim, num_classes):
    inputs = tf.keras.Input(shape=(feature_dim,))
    
    # Modified architecture for better generalization
    x = layers.Dense(2048)(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('swish')(x)  # Replace ReLU with Swish for better gradient flow
    x = layers.Dropout(0.4)(x)  # Increased dropout slightly (0.3 -> 0.4)
    
    # Add a residual connection
    residual = x  # Save for residual connection
    
    x = layers.Dense(1024)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('swish')(x)
    x = layers.Dropout(0.3)(x)  # Increased dropout slightly (0.2 -> 0.3)
    
    # Optional: Add a skip connection if shapes match
    if residual.shape[-1] == x.shape[-1]:
        x = layers.add([x, residual])
    else:
        # Use a projection if shapes don't match
        projection = layers.Dense(x.shape[-1], use_bias=False)(residual)
        x = layers.add([x, projection])
    
    # Add one more layer with L2 regularization for better generalization
    x = layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('swish')(x)
    x = layers.Dropout(0.2)(x)
    
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    
    # Original optimizer settings
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
    
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy', sparse_top_k_accuracy]
    )
    
    return model

class DynamicTrainingOptimizer(tf.keras.callbacks.Callback):
    """Dynamically adapt training parameters based on metrics patterns"""
    def __init__(self, patience=3):
        super().__init__()
        self.last_losses = []
        self.patience = patience
        self.last_lr_change = 0
        self.best_val_loss = float('inf')
        self.stagnation_count = 0
        self.lr_reductions = 0
        self.max_lr_reductions = 4  # Prevent too many reductions
        self.initial_lr = None
        
    def on_train_begin(self, logs=None):
        # Capture initial learning rate
        if hasattr(self.model.optimizer, 'lr'):
            if hasattr(self.model.optimizer.lr, '__call__'):
                # For LearningRateSchedule objects
                current_step = self.model.optimizer.iterations.numpy()
                self.initial_lr = float(self.model.optimizer.lr(current_step).numpy())
            else:
                # For fixed learning rates
                self.initial_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))
        
    def on_epoch_end(self, epoch, logs=None):
        if not logs or 'val_loss' not in logs:
            return
            
        val_loss = logs.get('val_loss')
        val_acc = logs.get('val_accuracy', 0)
        
        # Store loss history for trend analysis
        self.last_losses.append(val_loss)
        if len(self.last_losses) > self.patience:
            self.last_losses.pop(0)
        
        # Check for improvement
        if val_loss < self.best_val_loss:
            improvement = self.best_val_loss - val_loss
            self.best_val_loss = val_loss
            self.stagnation_count = 0
            print(f"{TermColors.GREEN}‚úì Validation improving by {improvement:.4f} - best loss: {val_loss:.4f}{TermColors.ENDC}")
        else:
            self.stagnation_count += 1
            print(f"{TermColors.YELLOW}‚ö† No improvement for {self.stagnation_count} epochs (best: {self.best_val_loss:.4f}, current: {val_loss:.4f}){TermColors.ENDC}")
            
        # Get current learning rate
        try:
            if hasattr(self.model.optimizer.lr, '__call__'):
                # For LearningRateSchedule objects
                current_step = self.model.optimizer.iterations.numpy()
                current_lr = float(self.model.optimizer.lr(current_step).numpy())
            else:
                # For fixed learning rates
                current_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))
        except:
            current_lr = 0.001  # Fallback
            
        # If enough history has been collected and we're past the early epochs
        if len(self.last_losses) >= self.patience and epoch > 5:
            # Check for worsening trend (consecutive increases in loss)
            if all(self.last_losses[i] > self.last_losses[i-1] for i in range(1, len(self.last_losses))):
                # Only reduce if we haven't reduced too many times already
                if self.lr_reductions < self.max_lr_reductions:
                    # Reduce LR more aggressively when loss is consistently increasing
                    new_lr = current_lr * 0.3  # More aggressive reduction
                    try:
                        tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                        print(f"{TermColors.YELLOW}‚ö†Ô∏è Loss consistently increasing - LR reduced: {current_lr:.6f} ‚Üí {new_lr:.6f}{TermColors.ENDC}")
                        self.lr_reductions += 1
                        self.last_losses = []  # Reset history after adjustment
                        self.last_lr_change = epoch
                    except:
                        print(f"{TermColors.RED}‚ùå Failed to update learning rate{TermColors.ENDC}")
                
            # Check for plateaus (minimal changes in loss)
            elif self.stagnation_count >= self.patience:
                diffs = [abs(self.last_losses[i] - self.last_losses[i-1]) for i in range(1, len(self.last_losses))]
                if all(d < 0.001 for d in diffs):  # Very small changes
                    # Try increasing the batch size if plateau detected
                    if epoch - self.last_lr_change > 5:
                        current_bs = self.model.get_config().get('batch_size', BATCH_SIZE)
                        if current_bs < 128:  # Don't go too large
                            # Rather than changing batch size (which is tricky), adjust learning rate instead
                            new_lr = current_lr * 0.5
                            if new_lr >= 1e-6:  # Don't go too small
                                try:
                                    tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                                    print(f"{TermColors.CYAN}üîÑ Plateau detected - Reducing learning rate: {current_lr:.6f} ‚Üí {new_lr:.6f}{TermColors.ENDC}")
                                    self.lr_reductions += 1
                                    self.last_lr_change = epoch
                                except:
                                    print(f"{TermColors.RED}‚ùå Failed to update learning rate{TermColors.ENDC}")
                
        # If accuracy is already very high, fine-tune with smaller learning rate
        if val_acc > 0.9 and current_lr > 1e-5 and epoch - self.last_lr_change > 3:
            new_lr = current_lr * 0.5
            try:
                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                print(f"{TermColors.GREEN}‚úì High accuracy detected ({val_acc:.4f}) - Fine-tuning with lower LR: {new_lr:.6f}{TermColors.ENDC}")
                self.last_lr_change = epoch
            except:
                pass

class AdaptiveRegularization(tf.keras.callbacks.Callback):
    """Dynamically adjust regularization based on overfitting detection"""
    def __init__(self, model):
        super().__init__()
        self.model = model
        self.overfitting_streak = 0
        self.underfitting_streak = 0
        self.dropout_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Dropout)]
        self.regularization_changes = 0
        self.max_reg_changes = 3
        
    def on_epoch_end(self, epoch, logs=None):
        # Skip early epochs
        if epoch < 3:
            return
            
        # Check for overfitting by comparing train and val accuracy
        train_acc = logs.get('accuracy')
        val_acc = logs.get('val_accuracy')
        train_loss = logs.get('loss')
        val_loss = logs.get('val_loss')
        
        if train_acc is not None and val_acc is not None:
            gap = train_acc - val_acc
            loss_gap = val_loss - train_loss
            
            # Detect significant overfitting gap
            if gap > 0.1:  # 10% gap indicates overfitting
                self.overfitting_streak += 1
                self.underfitting_streak = 0
                
                if self.overfitting_streak >= 3 and self.regularization_changes < self.max_reg_changes:  # 3 consecutive epochs showing overfitting
                    print(f"{TermColors.YELLOW}‚ö†Ô∏è Overfitting detected (acc gap: {gap:.2f}, loss gap: {loss_gap:.2f}) - Increasing regularization{TermColors.ENDC}")
                    
                    # Increase dropout rates if we can
                    if self.dropout_layers:
                        for layer in self.dropout_layers:
                            current_rate = tf.keras.backend.get_value(layer.rate)
                            new_rate = min(current_rate + 0.05, 0.7)  # Don't go beyond 0.7
                            layer.rate = new_rate
                            print(f"{TermColors.CYAN}‚Üë Dropout adjusted: {current_rate:.2f} ‚Üí {new_rate:.2f}{TermColors.ENDC}")
                        
                        self.regularization_changes += 1
                        self.overfitting_streak = 0  # Reset after adjustment
            
            # Detect underfitting (training and validation both low but close)
            elif gap < 0.03 and train_acc < 0.5 and epoch# filepath: c:\Users\stefa\Desktop\New folder\Scripts\Plant_regonition.py
import tensorflow as tf
import tensorflow_addons as tfa
from tensorflow.keras import layers, models, mixed_precision
from tensorflow.keras.applications import MobileNetV3Large
from tensorflow.keras.applications import DenseNet121
from tensorflow.keras.optimizers.schedules import CosineDecay
import os
import json
import time
import signal
import threading
import numpy as np
from tqdm.auto import tqdm
import logging
from datetime import datetime, timedelta
import sys
import glob
from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau
import psutil
import pickle
import gc
import types
import multiprocessing
from concurrent.futures import ThreadPoolExecutor
import concurrent.futures
import shutil
import traceback
import colorama
import sklearn
from sklearn.model_selection import train_test_split
from sklearn.utils.class_weight import compute_class_weight
from sklearn.preprocessing import StandardScaler
import os

# Define TermColors before using it
class TermColors:
    HEADER = '\033[95m'
    BLUE = '\033[94m'
    CYAN = '\033[96m'
    GREEN = '\033[92m'
    YELLOW = '\033[93m'
    RED = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

# Define memory limit function first thing after imports
def limit_memory_usage(gpu_memory_limit_mb=2048, ram_percent_limit=75):
    """Limit both GPU and RAM memory usage to prevent crashes
    
    Args:
        gpu_memory_limit_mb: GPU memory limit in megabytes (default: 2GB)
        ram_percent_limit: Maximum RAM usage allowed as percentage (default: 75%)
    """
    print(f"{TermColors.YELLOW}‚ö†Ô∏è MEMORY LIMITER ACTIVE{TermColors.ENDC}")
    
    # 1. GPU Memory Limiting
    physical_devices = tf.config.list_physical_devices('GPU')
    if physical_devices:
        try:
            # Set memory limit on each GPU
            for device in physical_devices:
                tf.config.set_logical_device_configuration(
                    device,
                    [tf.config.LogicalDeviceConfiguration(memory_limit=gpu_memory_limit_mb)]
                )
            print(f"{TermColors.GREEN}‚úÖ GPU memory limited to {gpu_memory_limit_mb}MB{TermColors.ENDC}")
        except Exception as e:
            print(f"{TermColors.RED}‚ùå Error setting GPU memory limit: {e}{TermColors.ENDC}")
    else:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è No GPU devices found to apply memory limit{TermColors.ENDC}")
    
    # 2. RAM Memory Monitoring Thread
    def ram_monitor_thread(ram_limit=ram_percent_limit):
        """Background thread to monitor RAM usage and prevent crashes"""
        print(f"{TermColors.GREEN}‚úÖ RAM monitor started (limit: {ram_limit}%){TermColors.ENDC}")
        while True:
            try:
                # Check current RAM usage
                mem = psutil.virtual_memory()
                if mem.percent > ram_limit:
                    print(f"{TermColors.RED}‚ö†Ô∏è RAM usage critical: {mem.percent}% > {ram_limit}%{TermColors.ENDC}")
                    print(f"{TermColors.YELLOW}‚è∏Ô∏è Force releasing memory...{TermColors.ENDC}")
                        
                    # Force garbage collection
                    gc.collect()
                        
                    # Try to release large objects
                    for obj in gc.get_objects():
                        try:
                            if isinstance(obj, (np.ndarray, tf.Tensor)):
                                if hasattr(obj, 'nbytes') and getattr(obj, 'nbytes', 0) > 1e6:
                                    del obj
                        except Exception:
                            pass
                        
                    # For extreme cases, try to reduce TensorFlow memory
                    if mem.percent > ram_limit + 10:
                        print(f"{TermColors.RED}üö® CRITICAL RAM USAGE: {mem.percent}%{TermColors.ENDC}")
                        tf.keras.backend.clear_session()
                        # Sleep to allow system to recover
                        time.sleep(5)
                            
                # Check less frequently when RAM usage is normal    
                time.sleep(5 if mem.percent > ram_limit - 10 else 30)
                    
            except Exception as e:
                # Don't let monitoring thread crash
                print(f"{TermColors.RED}‚ùå RAM monitor error: {e}{TermColors.ENDC}")
                time.sleep(60)
    
    # Start RAM monitor in background
    try:
        ram_thread = threading.Thread(target=ram_monitor_thread, args=(ram_percent_limit,), daemon=True)
        ram_thread.start()
    except Exception as e:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Could not start RAM monitor: {e}{TermColors.ENDC}")

# Apply memory limits immediately
limit_memory_usage(6144, 75)  # Using 6GB of GPU memory and 75% RAM threshold

os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'  # 0=all, 1=no INFO, 2=no WARNING, 3=no ERROR
tf.get_logger().setLevel('ERROR')

print(f"\n{TermColors.GREEN}‚úÖ TensorFlow is using GPU: {tf.test.is_gpu_available()}{TermColors.ENDC}")

# Force TensorFlow to see and use the GPU correctly
print("TensorFlow version:", tf.__version__)
print("Num GPUs Available: ", len(tf.config.experimental.list_physical_devices('GPU')))

# Force device placement logging
tf.debugging.set_log_device_placement(False)

# Configure TensorFlow to use the GPU 
physical_devices = tf.config.list_physical_devices('GPU')
if physical_devices:
    print("GPU is available:", physical_devices)
    try:
        # Only allow TensorFlow to see the first GPU
        tf.config.set_visible_devices(physical_devices[0], 'GPU')
        logical_devices = tf.config.list_logical_devices('GPU')
        print("Logical GPU devices:", logical_devices)
        print("Successfully configured GPU")
    except RuntimeError as e:
        print("GPU configuration error:", e)
else:
    print("‚ö†Ô∏è WARNING: No GPU found. Running on CPU only!")

# Initialize colorama for cross-platform colored terminal output
colorama.init()

# Configuration
DATA_DIR = r"C:\Users\stefa\Desktop\New folder\data\completed_images"
FEATURES_DIR = r"C:\Users\stefa\Desktop\New folder\data\features"
MODEL_DIR = r"C:\Users\stefa\Desktop\New folder\models"
CHECKPOINT_DIR = r"C:\Users\stefa\Desktop\New folder\checkpoints"
LOG_DIR = r"C:\Users\stefa\Desktop\New folder\logs"
STATS_DIR = r"C:\Users\stefa\Desktop\New folder\stats"

# Training Parameters
BATCH_SIZE = 32
IMAGE_SIZE = (224, 224)
EPOCHS = 50
MAX_CLASSES_PER_CHUNK = 1000
TOP_K = 10
INITIAL_LR = 1e-3
CPU_WORKERS = min(6, multiprocessing.cpu_count() - 1)  # Leave one core free
GRADIENT_ACCUMULATION_STEPS = 4
MEMORY_CLEANUP_FREQ = 500

# Create required directories
for directory in [FEATURES_DIR, MODEL_DIR, CHECKPOINT_DIR, LOG_DIR, STATS_DIR]:
    os.makedirs(directory, exist_ok=True)

# Enable mixed precision for better GPU performance
mixed_precision.set_global_policy('float32')

# Metrics formatting
def format_metrics(metrics_dict):
    """Format metrics dictionary into colored string"""
    formatted = []
    for key, value in metrics_dict.items():
        if isinstance(value, str):
            # Handle string values
            formatted.append(f"{key}: {value}")
        elif 'accuracy' in key:
            color = TermColors.GREEN
            formatted.append(f"{color}{key}: {value:.4f}{TermColors.ENDC}")
        elif 'loss' in key:
            color = TermColors.RED
            formatted.append(f"{color}{key}: {value:.4f}{TermColors.ENDC}")
        else:
            formatted.append(f"{key}: {value:.4f}")
    return " | ".join(formatted)

# Custom tqdm for showing metrics
class MetricsTQDM(tqdm):
    """Custom tqdm progress bar that displays training metrics"""
    def __init__(self, *args, **kwargs):
        # Initialize metrics and flag before super().__init__
        self.metrics = {}
        self._metrics_updated = False
        # Now call the parent constructor
        super().__init__(*args, **kwargs)
        
    def update_metrics(self, epoch, metrics):
        """Update training metrics in history"""
        self.current_epoch = epoch
        for key, value in metrics.items():
            if key not in self.history:
                self.history[key] = []
            # Ensure we don't have more entries than epochs
            while len(self.history[key]) <= epoch:
                self.history[key].append(None)
            
            # Handle non-numeric types properly
            try:
                # Try to convert to float
                self.history[key][epoch] = float(value)
            except (ValueError, TypeError):
                # If conversion fails, store as string representation
                self.history[key][epoch] = str(value)
        
        # Update best metrics
        val_loss = metrics.get('val_loss')
        val_accuracy = metrics.get('val_accuracy')
        
        if val_loss is not None and isinstance(val_loss, (float, int)):
            if val_loss < self.best_val_loss:
                self.best_val_loss = val_loss
                self.epochs_without_improvement = 0
            else:
                self.epochs_without_improvement += 1
        
        if val_accuracy is not None and isinstance(val_accuracy, (float, int)):
            if val_accuracy > self.best_val_accuracy:
                self.best_val_accuracy = val_accuracy
        
        self.save_state()
        
    def display(self, msg=None, pos=None):
        """Override display to include metrics"""
        # We don't need special handling anymore - postfix is set directly in update_metrics
        return super().display(msg, pos)

# Training state management
class TrainingState:
    """Manages training state for pause/resume functionality"""
    def __init__(self, state_file=os.path.join(CHECKPOINT_DIR, "training_state.json")):
        self.state_file = state_file
        self.current_chunk = 0
        self.current_epoch = 0
        self.processed_chunks = []
        self.history = {}
        self.best_val_loss = float('inf')
        self.best_val_accuracy = 0
        self.epochs_without_improvement = 0
        self.load_state()
    
    def load_state(self):
        """Load saved training state if exists"""
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
                    self.current_chunk = state.get('current_chunk', 0)
                    self.current_epoch = state.get('current_epoch', 0)
                    self.processed_chunks = state.get('processed_chunks', [])
                    self.history = state.get('history', {})
                    self.best_val_loss = state.get('best_val_loss', float('inf'))
                    self.best_val_accuracy = state.get('best_val_accuracy', 0)
                print(f"{TermColors.GREEN}‚úÖ Resuming from chunk {self.current_chunk}, epoch {self.current_epoch}{TermColors.ENDC}")
            except Exception as e:
                print(f"{TermColors.YELLOW}‚ö†Ô∏è Could not load training state: {e}{TermColors.ENDC}")
    
    def save_state(self):
        """Save current training state"""
        state = {
            'current_chunk': self.current_chunk,
            'current_epoch': self.current_epoch,
            'processed_chunks': self.processed_chunks,
            'history': self.history,
            'best_val_loss': self.best_val_loss,
            'best_val_accuracy': self.best_val_accuracy,
            'last_updated': datetime.now().isoformat()
        }
        with open(self.state_file, 'w') as f:
            json.dump(state, f, indent=2)
    
    def update_metrics(self, epoch, metrics):
        """Update training metrics in history"""
        self.current_epoch = epoch
        for key, value in metrics.items():
            if key not in self.history:
                self.history[key] = []
            # Ensure we don't have more entries than epochs
            while len(self.history[key]) <= epoch:
                self.history[key].append(None)
            self.history[key][epoch] = float(value)
        
        # Update best metrics
        val_loss = metrics.get('val_loss')
        val_accuracy = metrics.get('val_accuracy')
        
        if val_loss is not None and val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.epochs_without_improvement = 0
        else:
            self.epochs_without_improvement += 1
        
        if val_accuracy is not None and val_accuracy > self.best_val_accuracy:
            self.best_val_accuracy = val_accuracy
        
        self.save_state()
    
    def mark_chunk_complete(self, chunk_idx):
        """Mark a chunk as completely processed"""
        if chunk_idx not in self.processed_chunks:
            self.processed_chunks.append(chunk_idx)
        self.current_chunk = chunk_idx + 1
        self.current_epoch = 0
        self.best_val_loss = float('inf')
        self.best_val_accuracy = 0
        self.epochs_without_improvement = 0
        self.history = {}
        self.save_state()

def load_and_preprocess_image(img_path):
    """Load and preprocess a single image file"""
    try:
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
        img = tf.keras.preprocessing.image.img_to_array(img)
        img = img / 255.0
        return img
    except Exception:
        return None

def preprocess_image_enhanced(img_path):
    """Enhanced preprocessing with advanced augmentation"""
    try:
        # Load image
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
        img_array = tf.keras.preprocessing.image.img_to_array(img)
        
        # Create multiple augmented versions
        augmented_images = []
        
        # Original image with proper preprocessing
        img_orig = tf.keras.applications.convnext.preprocess_input(img_array.copy())
        augmented_images.append(img_orig)
        
        # Slight rotation (common in plant photos)
        img_rot = tf.keras.preprocessing.image.apply_affine_transform(
            img_array.copy(), theta=np.random.uniform(-20, 20))
        img_rot = tf.keras.applications.convnext.preprocess_input(img_rot)
        augmented_images.append(img_rot)
        
        # Slight zoom (simulate different distances)
        img_zoom = tf.keras.preprocessing.image.apply_affine_transform(
            img_array.copy(), zx=np.random.uniform(0.8, 1.2), zy=np.random.uniform(0.8, 1.2))
        img_zoom = tf.keras.applications.convnext.preprocess_input(img_zoom)
        augmented_images.append(img_zoom)
        
        # Changes in brightness/contrast
        img_bright = img_array.copy() * np.random.uniform(0.8, 1.2)
        img_bright = np.clip(img_bright, 0, 255)
        img_bright = tf.keras.applications.convnext.preprocess_input(img_bright)
        augmented_images.append(img_bright)
        
        # Random crop with padding
        img_crop = tf.keras.preprocessing.image.apply_affine_transform(
            img_array.copy(), zx=0.8, zy=0.8)
        img_crop = tf.keras.applications.convnext.preprocess_input(img_crop)
        augmented_images.append(img_crop)
        
        return augmented_images
    except Exception as e:
        print(f"Error processing {img_path}: {e}")
        return None

# Define metrics functions
def sparse_top_k_accuracy(y_true, y_pred):
    """Calculate top-K accuracy for sparse labels"""
    return tf.keras.metrics.sparse_top_k_categorical_accuracy(y_true, y_pred, k=TOP_K)

# Custom callbacks
class MetricsDisplayCallback(tf.keras.callbacks.Callback):
    """Display metrics during training with progress bars"""
    def __init__(self, total_epochs, validation_data=None, training_state=None):
        super().__init__()
        self.epoch_bar = None
        self.batch_bar = None
        self.total_epochs = total_epochs
        self.training_state = training_state
        self.validation_data = validation_data
        self.start_time = None
        self.epoch_times = []
        self.current_metrics = {}
        self.stop_flag = False
        
        # Setup signal handler for graceful stopping
        self.original_sigint = signal.getsignal(signal.SIGINT)
        signal.signal(signal.SIGINT, self._signal_handler)
        
    def _signal_handler(self, sig, frame):
        """Handle Ctrl+C signal gracefully"""
        print(f"\n{TermColors.YELLOW}‚è∏Ô∏è Training pause requested (Ctrl+C). Will stop after current batch.{TermColors.ENDC}")
        self.stop_flag = True
        self.model.stop_training = True
    
    def check_keyboard_shortcut(self):
        """Check if Ctrl+Alt+C is pressed to stop training gracefully"""
        try:
            # Check if keyboard module is imported, if not, import it
            try:
                import keyboard
            except ImportError:
                print(f"{TermColors.YELLOW}‚ö†Ô∏è Keyboard module not found. Installing...{TermColors.ENDC}")
                import subprocess
                subprocess.check_call([sys.executable, "-m", "pip", "install", "keyboard"])
                import keyboard
                
            if keyboard.is_pressed('ctrl+alt+c'):
                print(f"\n{TermColors.YELLOW}‚è∏Ô∏è Training pause requested (Ctrl+Alt+C). Will stop after current batch.{TermColors.ENDC}")
                self.stop_flag = True
                self.model.stop_training = True
                return True
            return False
        except Exception as e:
            # If keyboard monitoring fails, silently continue
            return False
    
    def on_train_begin(self, logs=None):
        self.start_time = time.time()
        print(f"{TermColors.HEADER}\n{'='*50}")
        print(f"BEGINNING MODEL TRAINING")
        print(f"{'='*50}{TermColors.ENDC}")
        print(f"{TermColors.CYAN}‚Ñπ Press Ctrl+Alt+C to stop training gracefully{TermColors.ENDC}")
        
        # Create epoch progress bar
        self.epoch_bar = tqdm(
            total=self.total_epochs, 
            desc="Epochs", 
            position=0, 
            leave=True,
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]'
        )
        
        # Update to starting epoch if resuming
        if self.training_state and self.training_state.current_epoch > 0:
            self.epoch_bar.update(self.training_state.current_epoch)
    
    def on_train_end(self, logs=None):
        self.stop_flag = True
        
        if self.epoch_bar:
            self.epoch_bar.close()
        if self.batch_bar:
            self.batch_bar.close()
        
        # Calculate and print training summary
        total_time = time.time() - self.start_time
        hours, remainder = divmod(total_time, 3600)
        minutes, seconds = divmod(remainder, 60)
        
        print(f"\n{TermColors.HEADER}{'='*50}")
        print(f"TRAINING COMPLETE")
        print(f"{'='*50}")
        print(f"Total training time: {int(hours)}h {int(minutes)}m {int(seconds)}s")
        print(f"Final metrics: {format_metrics(logs or {})}")
        print(f"{'='*50}{TermColors.ENDC}")
    
    def on_epoch_begin(self, epoch, logs=None):
        self.current_epoch_start = time.time()
        self.current_epoch = epoch
    
    # Use standard tqdm instead of MetricsTQDM
        self.batch_bar = tqdm(
            desc=f"Batch (Epoch {epoch+1}/{self.total_epochs})",
            total=self.params['steps'],
            position=1, 
            leave=False,
            unit='batch',
            bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}]'
        )
    
    def on_epoch_end(self, epoch, logs=None):
        """Update epoch progress bar and save metrics at the end of each epoch"""
        # Update epoch progress bar with metrics
        if self.epoch_bar:
            self.epoch_bar.update(1)
        
        # Calculate epoch time
        epoch_time = time.time() - self.current_epoch_start
        self.epoch_times.append(epoch_time)
        
        # Estimate remaining time
        if len(self.epoch_times) > 0:
            avg_epoch_time = sum(self.epoch_times) / len(self.epoch_times)
            remaining_epochs = self.total_epochs - (epoch + 1)
            eta_seconds = avg_epoch_time * remaining_epochs
            eta = str(timedelta(seconds=int(eta_seconds)))
            
            # Enhanced metrics display with better type handling
            metrics_display = []
            
            # Always show these metrics in this order if available
            priority_metrics = ['loss', 'val_loss', 'accuracy', 'val_accuracy', 'sparse_top_k_accuracy', 'val_sparse_top_k_accuracy']
            
            for metric in priority_metrics:
                if metric in logs:
                    value = logs[metric]
                    # Check if value is a formatting-compatible type
                    if isinstance(value, (float, int, np.float32, np.float64, np.int32, np.int64)):
                        if 'loss' in metric:
                            color = TermColors.RED
                            metrics_display.append(f"{color}{metric}: {value:.4f}{TermColors.ENDC}")
                        elif 'accuracy' in metric:
                            color = TermColors.GREEN
                            metrics_display.append(f"{color}{metric}: {value:.4f}{TermColors.ENDC}")
                        else:
                            metrics_display.append(f"{metric}: {value:.4f}")
                    else:
                        # Handle non-numeric types like CosineDecay
                        metrics_display.append(f"{metric}: {str(value)}")
            
            # Add any remaining metrics with type checking
            for metric, value in logs.items():
                if metric not in priority_metrics:
                    if isinstance(value, (float, int, np.float32, np.float64, np.int32, np.int64)):
                        metrics_display.append(f"{metric}: {value:.4f}")
                    else:
                        metrics_display.append(f"{metric}: {str(value)}")
            
            metrics_str = " | ".join(metrics_display)
            self.epoch_bar.set_postfix_str(f"ETA: {eta} | {metrics_str}")
        
        # Close batch progress bar
        if self.batch_bar:
            self.batch_bar.close()
            self.batch_bar = None
        
        # Save metrics in training state
        if self.training_state and logs:
            # Create a copy of logs with only serializable values
            filtered_logs = {}
            for key, value in (logs or {}).items():
                # Remove learning rate schedule objects that can't be serialized
                if key == 'lr' and not isinstance(value, (float, int, np.float32, np.float64)):
                    # Try to extract current lr value if possible
                    try:
                        if hasattr(value, '__call__'):
                            step = self.model.optimizer.iterations.numpy()
                            filtered_logs[key] = float(value(step).numpy())
                        else:
                            filtered_logs[key] = str(value)
                    except:
                        filtered_logs[key] = f"<schedule>"
                elif isinstance(value, (float, int, np.float32, np.float64, np.int32, np.int64)):
                    filtered_logs[key] = float(value)
                else:
                    filtered_logs[key] = str(value)
                    
            self.training_state.update_metrics(epoch, filtered_logs)
    
    def on_batch_end(self, batch, logs=None):
        if self.batch_bar:
            self.batch_bar.update(1)
        
        # Only update metrics display periodically to reduce overhead
        if batch % 10 == 0 and logs:
            # Format metrics string directly
            metrics_str = ""
            for k, v in logs.items():
                if isinstance(v, str):
                    metrics_str += f" | {k}: {v}"
                elif 'loss' in k:
                    metrics_str += f" | {TermColors.RED}{k}: {v:.4f}{TermColors.ENDC}"
                elif 'accuracy' in k:
                    metrics_str += f" | {TermColors.GREEN}{k}: {v:.4f}{TermColors.ENDC}"
                else:
                    metrics_str += f" | {k}: {v:.4f}"
                    
            # Update the description instead of using custom metrics display
            self.batch_bar.set_description(
                f"Batch (Epoch {self.current_epoch+1}/{self.total_epochs}){metrics_str}"
            )
            
            # Check for keyboard shortcut
            if batch % 10 == 0:
                self.check_keyboard_shortcut()
    
    # Check for stop flag
        if self.stop_flag:
            self.model.stop_training = True

class AutoTrainingConfig(tf.keras.callbacks.Callback):
    """Automatically adjust training parameters based on performance"""
    def __init__(self, initial_lr=INITIAL_LR, training_state=None):
        super().__init__()
        self.initial_lr = initial_lr
        self.training_state = training_state
        self.plateau_count = 0
        self.best_val_loss = float('inf')
    
    def on_epoch_end(self, epoch, logs=None):
        if not logs or 'val_loss' not in logs:
            return
            
        val_loss = logs['val_loss']
        
        # Fixed: Handle CosineDecay learning rate correctly
        try:
            if hasattr(self.model.optimizer.lr, '__call__'):
                # For LearningRateSchedule objects like CosineDecay
                current_step = self.model.optimizer.iterations.numpy()
                current_lr = self.model.optimizer.lr(current_step).numpy()
            else:
                # For fixed learning rates
                current_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))
        except:
            # Fallback if we can't get the learning rate
            current_lr = 0.001
        
        # Check if validation loss improved
        if val_loss < self.best_val_loss:
            self.best_val_loss = val_loss
            self.plateau_count = 0
            print(f"{TermColors.GREEN}‚úì Validation loss improved to {val_loss:.4f}{TermColors.ENDC}")
        else:
            self.plateau_count += 1
            print(f"{TermColors.YELLOW}‚ö† Validation loss plateau: {self.plateau_count} epochs without improvement{TermColors.ENDC}")
            
            # If we have a plateau for too long, adjust learning rate
            if self.plateau_count >= 3:
                new_lr = current_lr * 0.5
                if new_lr < 1e-6:  # Don't go too low
                    new_lr = 1e-6
                
                print(f"{TermColors.YELLOW}‚öô Reducing learning rate: {current_lr:.6f} ‚Üí {new_lr:.6f}{TermColors.ENDC}")
                # Set the new learning rate safely
                try:
                    tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                except:
                    print(f"{TermColors.YELLOW}‚ö† Could not update learning rate - using schedule instead{TermColors.ENDC}")
                self.plateau_count = 0  # Reset counter after adjustment

# Advanced training configuration with gradual unfreezing
def create_custom_callbacks():
    class GradualUnfreezingCallback(tf.keras.callbacks.Callback):
        def __init__(self, model, feature_dim):
            super().__init__()
            self.model = model
            self.feature_dim = feature_dim
            self.unfrozen_layers = 0
            
        def on_epoch_end(self, epoch, logs=None):
            # Every 5 epochs, make the model slightly more complex
            if epoch > 0 and epoch % 5 == 0 and self.unfrozen_layers < 3:
                if self.unfrozen_layers == 0:
                    # Add a new layer
                    x = self.model.layers[-2].output
                    new_layer = layers.Dense(512, activation='swish')(x)
                    outputs = layers.Dense(self.model.output.shape[1], activation='softmax')(new_layer)
                    new_model = tf.keras.Model(inputs=self.model.input, outputs=outputs)
                    weights = self.model.get_weights()
                    self.model = new_model
                    self.model.compile(optimizer=self.model.optimizer, 
                                     loss='sparse_categorical_crossentropy',
                                     metrics=['accuracy', sparse_top_k_accuracy])
                    print(f"{TermColors.CYAN}‚ú® Added complexity at epoch {epoch+1}{TermColors.ENDC}")
                    
                self.unfrozen_layers += 1
    
    return [GradualUnfreezingCallback(model, feature_dim)]  # Add to your callbacks list

def analyze_features(features_file):
    """Analyze feature quality to detect problems"""
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"FEATURE QUALITY ANALYSIS")
    print(f"{'='*50}{TermColors.ENDC}")
    
    features, labels = load_features(features_file)
    
    # Check for NaN values
    nan_count = np.isnan(features).sum()
    if nan_count > 0:
        print(f"{TermColors.RED}‚ùå Found {nan_count} NaN values in features!{TermColors.ENDC}")
    
    # Check feature variance
    feature_variance = np.var(features, axis=0)
    low_variance = (feature_variance < 1e-5).sum()
    if low_variance > features.shape[1] // 2:
        print(f"{TermColors.RED}‚ùå {low_variance}/{features.shape[1]} features have very low variance!{TermColors.ENDC}")
    
    # Check for uniform distribution (indicates potential preprocessing issue)
    feature_ranges = np.ptp(features, axis=0)
    if np.mean(feature_ranges) < 0.1:
        print(f"{TermColors.RED}‚ùå Features have very small range (mean range: {np.mean(feature_ranges):.6f}){TermColors.ENDC}")
    
    # Check for class separability
    from sklearn.decomposition import PCA
    from sklearn.metrics import silhouette_score
    
    print(f"{TermColors.CYAN}‚Ñπ Analyzing class separability...{TermColors.ENDC}")
    
    # Use PCA to reduce dimensions 
    pca = PCA(n_components=min(100, features.shape[0]//10, features.shape[1]))
    reduced_features = pca.fit_transform(features)
    
    # Sample for silhouette score (max 10,000 samples)
    if len(features) > 10000:
        indices = np.random.choice(len(features), 10000, replace=False)
        sample_features = reduced_features[indices]
        sample_labels = labels[indices]
    else:
        sample_features = reduced_features
        sample_labels = labels
    
    try:
        silhouette = silhouette_score(sample_features, sample_labels)
        print(f"{TermColors.CYAN}‚Ñπ Class separability (silhouette score): {silhouette:.4f}{TermColors.ENDC}")
        
        if silhouette < 0.1:
            print(f"{TermColors.RED}‚ùå Poor class separability in features!{TermColors.ENDC}")
        elif silhouette < 0.3:
            print(f"{TermColors.YELLOW}‚ö†Ô∏è Mediocre class separability in features{TermColors.ENDC}")
        else:
            print(f"{TermColors.GREEN}‚úÖ Good class separability in features{TermColors.ENDC}")
    except:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Unable to calculate class separability{TermColors.ENDC}")
    
    # Check explained variance from PCA
    explained_variance = np.sum(pca.explained_variance_ratio_)
    print(f"{TermColors.CYAN}‚Ñπ Top 100 components explain {explained_variance:.2%} of variance{TermColors.ENDC}")
    
    if explained_variance < 0.5:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Features have high dimensionality with limited structure{TermColors.ENDC}")
    
    return features, labels

def analyze_plant_features(features, labels):
    """Specialized analysis for plant feature quality"""
    # Calculate inter-class similarity matrix
    from sklearn.metrics.pairwise import cosine_similarity
    
    # Sample for performance if needed
    if len(features) > 5000:
        indices = np.random.choice(len(features), 5000, replace=False)
        sample_features = features[indices]
        sample_labels = labels[indices]
    else:
        sample_features = features
        sample_labels = labels
    
    # Get unique classes
    unique_classes = np.unique(sample_labels)
    
    # Calculate class centroids
    centroids = []
    for cls in unique_classes:
        class_features = sample_features[sample_labels == cls]
        centroid = np.mean(class_features, axis=0)
        centroids.append(centroid)
    
    centroids = np.array(centroids)
    
    # Calculate similarity between class centroids
    similarity = cosine_similarity(centroids)
    np.fill_diagonal(similarity, 0)  # Remove self-similarity
    
    # Analyze potential confusion points
    high_similarity = np.where(similarity > 0.9)
    confusion_pairs = list(zip(high_similarity[0], high_similarity[1]))
    
    if confusion_pairs:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è Found {len(confusion_pairs)} potentially confusable class pairs{TermColors.ENDC}")
        # Print a few examples
        for i, j in confusion_pairs[:5]:
            print(f"  - Classes {unique_classes[i]} and {unique_classes[j]}: {similarity[i,j]:.4f} similarity")
    else:
        print(f"{TermColors.GREEN}‚úÖ No highly confusable classes detected{TermColors.ENDC}")
    
    # Return confusability score (lower is better)
    return np.mean(similarity)

def analyze_model_performance():
    """Analyze all chunk models and identify low-performing ones"""
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"ANALYZING CHUNK MODEL PERFORMANCE")
    print(f"{'='*50}{TermColors.ENDC}")
    
    model_files = glob.glob(os.path.join(MODEL_DIR, "chunk_*_metadata.json"))
    
    if not model_files:
        print(f"{TermColors.RED}‚ùå No model metadata files found{TermColors.ENDC}")
        return
        
    print(f"{TermColors.CYAN}‚Ñπ Found {len(model_files)} trained chunks{TermColors.ENDC}")
    
    # Track performance metrics
    all_performance = []
    problematic_chunks = []
    
    for metadata_file in model_files:
        chunk_idx = int(os.path.basename(metadata_file).split("_")[1])
        
        with open(metadata_file) as f:
            metadata = json.load(f)
            
        # Get performance metrics
        val_acc = metadata.get('performance', {}).get('val_accuracy', 0.0)
        val_top_k = metadata.get('performance', {}).get('val_sparse_top_k_accuracy', 0.0)
        num_classes = metadata.get('num_classes', 0)
        
        all_performance.append((chunk_idx, val_acc, val_top_k, num_classes))
        
        # Flag chunks with accuracy below threshold
        if val_acc < 0.6:  # 60% threshold
            problematic_chunks.append((chunk_idx, val_acc, val_top_k, num_classes))
    
    # Sort by accuracy
    all_performance.sort(key=lambda x: x[1])
    
    # Display overall statistics
    avg_acc = sum(p[1] for p in all_performance) / len(all_performance) if all_performance else 0
    avg_top_k = sum(p[2] for p in all_performance) / len(all_performance) if all_performance else 0
    
    print(f"\n{TermColors.CYAN}üìä OVERALL PERFORMANCE:{TermColors.ENDC}")
    print(f"Average accuracy: {avg_acc:.2%}")
    print(f"Average top-{TOP_K} accuracy: {avg_top_k:.2%}")
    
    # Display worst performing chunks
    print(f"\n{TermColors.YELLOW}‚ö†Ô∏è LOWEST PERFORMING CHUNKS:{TermColors.ENDC}")
    for i, (chunk_idx, acc, top_k, num_classes) in enumerate(all_performance[:5]):
        print(f"{i+1}. Chunk {chunk_idx}: Accuracy {acc:.2%}, Top-{TOP_K} {top_k:.2%} ({num_classes} classes)")
    
    # Display problematic chunks
    if problematic_chunks:
        print(f"\n{TermColors.RED}‚ùå PROBLEMATIC CHUNKS (Below 60% accuracy):{TermColors.ENDC}")
        for chunk_idx, acc, top_k, num_classes in problematic_chunks:
            print(f"Chunk {chunk_idx}: Accuracy {acc:.2%}, Top-{TOP_K} {top_k:.2%} ({num_classes} classes)")
        
        print(f"\n{TermColors.CYAN}‚ÑπÔ∏è To retrain problematic chunks, run:{TermColors.ENDC}")
        print(f"retrain_chunk([{', '.join(str(c[0]) for c in problematic_chunks)}])")
    else:
        print(f"\n{TermColors.GREEN}‚úÖ No problematic chunks detected!{TermColors.ENDC}")
        
    return problematic_chunks

def scan_class_directory(args):
        class_idx, class_dir = args
        class_name = os.path.basename(class_dir)
        paths = []
        indices = []
        
        for img_name in os.listdir(class_dir):
            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):
                img_path = os.path.join(class_dir, img_name)
                paths.append(img_path)
                indices.append(class_idx)
                
        return class_name, paths, indices

def extract_enhanced_features(class_dirs, chunk_idx):
    """Enhanced feature extraction using EfficientNetV2L with optimized resource utilization"""
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"HIGH-PERFORMANCE FEATURE EXTRACTION FOR CHUNK {chunk_idx+1}")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Setup keyboard interrupt checking
    stop_requested = False
    last_keyboard_check = time.time()
    
    def check_keyboard_interrupt():
        nonlocal stop_requested, last_keyboard_check
        current_time = time.time()
        if current_time - last_keyboard_check < 1.0:
            return stop_requested
        last_keyboard_check = current_time
        try:
            import keyboard
            if keyboard.is_pressed('ctrl+alt+c'):
                print(f"\n{TermColors.YELLOW}‚è∏Ô∏è Feature extraction pause requested (Ctrl+Alt+C). Will stop after current batch.{TermColors.ENDC}")
                stop_requested = True
                return True
        except Exception:
            pass
        return stop_requested

    # Use EfficientNetV2L with optimized settings
    with tf.device('/GPU:0'):
        # Use smaller model for faster processing while maintaining quality
        from tensorflow.keras.applications import EfficientNetV2L
        
        base_model = EfficientNetV2L(
            input_shape=(*IMAGE_SIZE, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        base_model.trainable = False
        feature_extractor = tf.keras.Model(inputs=base_model.input, outputs=base_model.output)
    
    feature_dim = feature_extractor.output_shape[1]
    print(f"{TermColors.GREEN}‚úÖ Feature extractor loaded: EfficientNetV2L ({feature_dim} dims){TermColors.ENDC}")
    
    # Storage for features - simple approach that worked before
    all_features = []
    all_labels = []
    class_names = []
    
    # Create chunk feature directory
    chunk_feature_dir = os.path.join(FEATURES_DIR, f"chunk_{chunk_idx}")
    os.makedirs(chunk_feature_dir, exist_ok=True)
    
    # Collect all image paths with parallel processing
    print(f"{TermColors.CYAN}‚Ñπ Collecting image paths with parallel processing{TermColors.ENDC}")
    
    all_image_paths = []
    all_class_indices = []
    
    # Use process pool for truly parallel directory scanning
    with multiprocessing.Pool(processes=CPU_WORKERS) as pool:
        results = list(tqdm(
            pool.imap(scan_class_directory, enumerate(class_dirs)),
            total=len(class_dirs),
            desc="Scanning classes",
            position=0
        ))
    
    # Combine results
    for class_name, paths, indices in results:
        class_names.append(class_name)
        all_image_paths.extend(paths)
        all_class_indices.extend(indices)
    
    total_images = len(all_image_paths)
    
    if total_images == 0:
        print(f"{TermColors.RED}‚ùå No valid images found in provided class directories!{TermColors.ENDC}")
        return None, None
    
    print(f"{TermColors.GREEN}‚úÖ Found {total_images} images across {len(class_names)} classes{TermColors.ENDC}")
    
    # Process in smaller batches to reduce memory usage
    batch_size = 64  # Smaller batch size to prevent memory issues
    print(f"{TermColors.CYAN}‚Ñπ Using batch size of {batch_size} for feature extraction{TermColors.ENDC}")
    
    # Create progress bar
    progress_bar = tqdm(total=total_images, desc="Extracting features", position=0)
    
    # Process images in batches
    for i in range(0, len(all_image_paths), batch_size):
        if check_keyboard_interrupt():
            print(f"{TermColors.YELLOW}‚ö†Ô∏è Feature extraction interrupted. Saving progress...{TermColors.ENDC}")
            break
        
        batch_paths = all_image_paths[i:i+batch_size]
        batch_indices = all_class_indices[i:i+batch_size]
        
        # Load and preprocess images
        batch_images = []
        valid_indices = []
        
        for j, (img_path, class_idx) in enumerate(zip(batch_paths, batch_indices)):
            try:
                img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
                img = tf.keras.preprocessing.image.img_to_array(img)
                img = tf.keras.applications.efficientnet_v2.preprocess_input(img)
                batch_images.append(img)
                valid_indices.append(class_idx)
            except Exception as e:
                print(f"Error loading image {img_path}: {e}")
        
        # Skip if no valid images in batch
        if not batch_images:
            continue
        
        # Convert to numpy array
        batch_array = np.array(batch_images)
        
        # Extract features
        batch_features = feature_extractor.predict(batch_array, verbose=0)
        
        # Store features and labels
        for feature, class_idx in zip(batch_features, valid_indices):
            all_features.append(feature)
            all_labels.append(class_idx)
        
        # Update progress bar
        progress_bar.update(len(batch_images))
        
        # Force garbage collection periodically
        if i % (batch_size * 10) == 0:
            gc.collect()
    
    progress_bar.close()
    
    # Save class mapping
    class_mapping = {idx: name for idx, name in enumerate(class_names)}
    with open(os.path.join(chunk_feature_dir, "class_mapping.json"), "w") as f:
        json.dump(class_mapping, f, indent=2)
    
    # Convert to numpy arrays
    if len(all_features) == 0:
        print(f"{TermColors.YELLOW}‚ö†Ô∏è No features extracted. Aborting.{TermColors.ENDC}")
        return None, None
    
    print(f"{TermColors.CYAN}‚Ñπ Saving {len(all_features)} features to disk{TermColors.ENDC}")
    features_array = np.array(all_features)
    labels_array = np.array(all_labels)
    
    # Save features to disk
    features_file = os.path.join(chunk_feature_dir, "features.npz")
    np.savez_compressed(features_file, features=features_array, labels=labels_array)
    
    print(f"{TermColors.GREEN}‚úÖ Features saved to {features_file}{TermColors.ENDC}")
    return features_file, class_mapping

def prune_features_rolling_window(current_chunk_idx, window_size=1):  # Reduced window size to 1
    """Aggressively remove feature files after model training to save disk space
    
    Args:
        current_chunk_idx: The chunk that was just processed
        window_size: Number of chunks to keep (default: 1 - only keep current chunk)
    """
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"AGGRESSIVE FEATURE MANAGEMENT")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Check all chunks up to the current one for possible deletion
    for chunk_to_check in range(current_chunk_idx + 1):  # Include current chunk in check
        # Skip the most recent chunks based on window_size
        if chunk_to_check > current_chunk_idx - window_size:
            continue
            
        # Check if this chunk's features exist
        chunk_feature_dir = os.path.join(FEATURES_DIR, f"chunk_{chunk_to_check}")
        feature_file = os.path.join(chunk_feature_dir, "features.npz")
        
        if os.path.exists(feature_file):
            # Check if model for this chunk exists (we don't want to delete features 
            # if the model doesn't exist or training failed)
            model_file = os.path.join(MODEL_DIR, f"chunk_{chunk_to_check}_model.keras")
            metadata_file = os.path.join(MODEL_DIR, f"chunk_{chunk_to_check}_metadata.json")
            
            if os.path.exists(model_file) and os.path.exists(metadata_file):
                # Get file size before deletion for reporting
                file_size_mb = os.path.getsize(feature_file) / (1024 * 1024)
                
                print(f"{TermColors.YELLOW}‚ö†Ô∏è Removing features for chunk {chunk_to_check} to save disk space ({file_size_mb:.2f} MB){TermColors.ENDC}")
                
                # Remove the feature file but keep the class mapping
                os.remove(feature_file)
                
                # Create a placeholder to indicate features were deleted
                with open(os.path.join(chunk_feature_dir, "features_pruned.txt"), "w") as f:
                    f.write(f"Features were pruned on {datetime.now().isoformat()} to save disk space.\n")
                    f.write(f"Original size: {file_size_mb:.2f} MB\n")
                    f.write(f"Model is preserved at: {model_file}\n")
                
                print(f"{TermColors.GREEN}‚úÖ Freed {file_size_mb:.2f} MB of disk space{TermColors.ENDC}")
            else:
                print(f"{TermColors.CYAN}‚Ñπ Keeping features for chunk {chunk_to_check} because model not found or incomplete{TermColors.ENDC}")

def load_features(features_file):
    """Load extracted features from file with verification to detect corruption"""
    print(f"{TermColors.CYAN}‚Ñπ Loading features from {features_file}{TermColors.ENDC}")
    
    # Add this corruption check before loading
    try:
        file_size = os.path.getsize(features_file)
        if file_size < 1000:  # Suspiciously small
            print(f"{TermColors.RED}‚ö†Ô∏è Feature file appears corrupted (only {file_size} bytes){TermColors.ENDC}")
            raise ValueError("Feature file too small, likely corrupted")
            
        # Now proceed with loading
        load_bar = tqdm(total=1, desc="Loading features")
        data = np.load(features_file)
        features = data['features']
        labels = data['labels']
        load_bar.update(1)
        load_bar.close()
        
        print(f"{TermColors.GREEN}‚úÖ Loaded {features.shape[0]} features with {features.shape[1]} dimensions{TermColors.ENDC}")
        return features, labels
        
    except Exception as e:
        print(f"{TermColors.RED}‚ùå Error loading features: {e}{TermColors.ENDC}")
        return None, None

# Memory management function with proper gc import
def clean_memory():
    """Aggressively clean memory between processing steps with time-based cleanup"""
    # Static variable to track last cleanup time
    if not hasattr(clean_memory, "last_cleanup_time"):
        clean_memory.last_cleanup_time = time.time()
    
    current_time = time.time()
    should_deep_clean = (current_time - clean_memory.last_cleanup_time) >= 60  # 60 seconds = 1 minute
    
    # Check current memory usage
    mem = psutil.virtual_memory()
    force_cleanup = mem.percent > 85  # Force cleanup if memory usage is above 85%
    
    # Basic cleanup always happens
    tf.keras.backend.clear_session()
    gc.collect()
    
    # Deep cleanup happens every minute OR when memory usage is high
    if should_deep_clean or force_cleanup:
        if force_cleanup:
            print(f"{TermColors.RED}‚ö†Ô∏è High memory usage detected ({mem.percent}%). Performing emergency cleanup.{TermColors.ENDC}")
        else:
            print(f"{TermColors.CYAN}‚Ñπ Performing scheduled deep memory cleanup{TermColors.ENDC}")
        
        # More aggressive garbage collection
        for _ in range(5):  # Multiple collection cycles
            gc.collect()
        
        # Try to release GPU memory if possible
        gpus = tf.config.experimental.list_physical_devices('GPU')
        if gpus:
            try:
                # Reset TensorFlow session
                tf.keras.backend.clear_session()
                
                # Extra GPU memory cleanup
                print(f"{TermColors.CYAN}‚Ñπ Releasing GPU memory{TermColors.ENDC}")
            except:
                pass
        
        # Update last cleanup time
        clean_memory.last_cleanup_time = current_time

# In your build_model function, add attention mechanism
def build_model(feature_dim, num_classes):
    inputs = tf.keras.Input(shape=(feature_dim,))
    
    # Modified architecture for better generalization
    x = layers.Dense(2048)(inputs)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('swish')(x)  # Replace ReLU with Swish for better gradient flow
    x = layers.Dropout(0.4)(x)  # Increased dropout slightly (0.3 -> 0.4)
    
    # Add a residual connection
    residual = x  # Save for residual connection
    
    x = layers.Dense(1024)(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('swish')(x)
    x = layers.Dropout(0.3)(x)  # Increased dropout slightly (0.2 -> 0.3)
    
    # Optional: Add a skip connection if shapes match
    if residual.shape[-1] == x.shape[-1]:
        x = layers.add([x, residual])
    else:
        # Use a projection if shapes don't match
        projection = layers.Dense(x.shape[-1], use_bias=False)(residual)
        x = layers.add([x, projection])
    
    # Add one more layer with L2 regularization for better generalization
    x = layers.Dense(512, kernel_regularizer=tf.keras.regularizers.l2(0.001))(x)
    x = layers.BatchNormalization()(x)
    x = layers.Activation('swish')(x)
    x = layers.Dropout(0.2)(x)
    
    outputs = layers.Dense(num_classes, activation='softmax')(x)
    
    model = tf.keras.Model(inputs=inputs, outputs=outputs)
    
    # Original optimizer settings
    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)
    
    model.compile(
        optimizer=optimizer,
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy', sparse_top_k_accuracy]
    )
    
    return model

class DynamicTrainingOptimizer(tf.keras.callbacks.Callback):
    """Dynamically adapt training parameters based on metrics patterns"""
    def __init__(self, patience=3):
        super().__init__()
        self.last_losses = []
        self.patience = patience
        self.last_lr_change = 0
        self.best_val_loss = float('inf')
        self.stagnation_count = 0
        self.lr_reductions = 0
        self.max_lr_reductions = 4  # Prevent too many reductions
        self.initial_lr = None
        
    def on_train_begin(self, logs=None):
        # Capture initial learning rate
        if hasattr(self.model.optimizer, 'lr'):
            if hasattr(self.model.optimizer.lr, '__call__'):
                # For LearningRateSchedule objects
                current_step = self.model.optimizer.iterations.numpy()
                self.initial_lr = float(self.model.optimizer.lr(current_step).numpy())
            else:
                # For fixed learning rates
                self.initial_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))
        
    def on_epoch_end(self, epoch, logs=None):
        if not logs or 'val_loss' not in logs:
            return
            
        val_loss = logs.get('val_loss')
        val_acc = logs.get('val_accuracy', 0)
        
        # Store loss history for trend analysis
        self.last_losses.append(val_loss)
        if len(self.last_losses) > self.patience:
            self.last_losses.pop(0)
        
        # Check for improvement
        if val_loss < self.best_val_loss:
            improvement = self.best_val_loss - val_loss
            self.best_val_loss = val_loss
            self.stagnation_count = 0
            print(f"{TermColors.GREEN}‚úì Validation improving by {improvement:.4f} - best loss: {val_loss:.4f}{TermColors.ENDC}")
        else:
            self.stagnation_count += 1
            print(f"{TermColors.YELLOW}‚ö† No improvement for {self.stagnation_count} epochs (best: {self.best_val_loss:.4f}, current: {val_loss:.4f}){TermColors.ENDC}")
            
        # Get current learning rate
        try:
            if hasattr(self.model.optimizer.lr, '__call__'):
                # For LearningRateSchedule objects
                current_step = self.model.optimizer.iterations.numpy()
                current_lr = float(self.model.optimizer.lr(current_step).numpy())
            else:
                # For fixed learning rates
                current_lr = float(tf.keras.backend.get_value(self.model.optimizer.lr))
        except:
            current_lr = 0.001  # Fallback
            
        # If enough history has been collected and we're past the early epochs
        if len(self.last_losses) >= self.patience and epoch > 5:
            # Check for worsening trend (consecutive increases in loss)
            if all(self.last_losses[i] > self.last_losses[i-1] for i in range(1, len(self.last_losses))):
                # Only reduce if we haven't reduced too many times already
                if self.lr_reductions < self.max_lr_reductions:
                    # Reduce LR more aggressively when loss is consistently increasing
                    new_lr = current_lr * 0.3  # More aggressive reduction
                    try:
                        tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                        print(f"{TermColors.YELLOW}‚ö†Ô∏è Loss consistently increasing - LR reduced: {current_lr:.6f} ‚Üí {new_lr:.6f}{TermColors.ENDC}")
                        self.lr_reductions += 1
                        self.last_losses = []  # Reset history after adjustment
                        self.last_lr_change = epoch
                    except:
                        print(f"{TermColors.RED}‚ùå Failed to update learning rate{TermColors.ENDC}")
                
            # Check for plateaus (minimal changes in loss)
            elif self.stagnation_count >= self.patience:
                diffs = [abs(self.last_losses[i] - self.last_losses[i-1]) for i in range(1, len(self.last_losses))]
                if all(d < 0.001 for d in diffs):  # Very small changes
                    # Try increasing the batch size if plateau detected
                    if epoch - self.last_lr_change > 5:
                        current_bs = self.model.get_config().get('batch_size', BATCH_SIZE)
                        if current_bs < 128:  # Don't go too large
                            # Rather than changing batch size (which is tricky), adjust learning rate instead
                            new_lr = current_lr * 0.5
                            if new_lr >= 1e-6:  # Don't go too small
                                try:
                                    tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                                    print(f"{TermColors.CYAN}üîÑ Plateau detected - Reducing learning rate: {current_lr:.6f} ‚Üí {new_lr:.6f}{TermColors.ENDC}")
                                    self.lr_reductions += 1
                                    self.last_lr_change = epoch
                                except:
                                    print(f"{TermColors.RED}‚ùå Failed to update learning rate{TermColors.ENDC}")
                
        # If accuracy is already very high, fine-tune with smaller learning rate
        if val_acc > 0.9 and current_lr > 1e-5 and epoch - self.last_lr_change > 3:
            new_lr = current_lr * 0.5
            try:
                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)
                print(f"{TermColors.GREEN}‚úì High accuracy detected ({val_acc:.4f}) - Fine-tuning with lower LR: {new_lr:.6f}{TermColors.ENDC}")
                self.last_lr_change = epoch
            except:
                pass

class AdaptiveRegularization(tf.keras.callbacks.Callback):
    """Dynamically adjust regularization based on overfitting detection"""
    def __init__(self, model):
        super().__init__()
        self.model = model
        self.overfitting_streak = 0
        self.underfitting_streak = 0
        self.dropout_layers = [layer for layer in model.layers if isinstance(layer, tf.keras.layers.Dropout)]
        self.regularization_changes = 0
        self.max_reg_changes = 3
        
    def on_epoch_end(self, epoch, logs=None):
        # Skip early epochs
        if epoch < 3:
            return
            
        # Check for overfitting by comparing train and val accuracy
        train_acc = logs.get('accuracy')
        val_acc = logs.get('val_accuracy')
        train_loss = logs.get('loss')
        val_loss = logs.get('val_loss')
        
        if train_acc is not None and val_acc is not None:
            gap = train_acc - val_acc
            loss_gap = val_loss - train_loss
            
            # Detect significant overfitting gap
            if gap > 0.1:  # 10% gap indicates overfitting
                self.overfitting_streak += 1
                self.underfitting_streak = 0
                
                if self.overfitting_streak >= 3 and self.regularization_changes < self.max_reg_changes:  # 3 consecutive epochs showing overfitting
                    print(f"{TermColors.YELLOW}‚ö†Ô∏è Overfitting detected (acc gap: {gap:.2f}, loss gap: {loss_gap:.2f}) - Increasing regularization{TermColors.ENDC}")
                    
                    # Increase dropout rates if we can
                    if self.dropout_layers:
                        for layer in self.dropout_layers:
                            current_rate = tf.keras.backend.get_value(layer.rate)
                            new_rate = min(current_rate + 0.05, 0.7)  # Don't go beyond 0.7
                            layer.rate = new_rate
                            print(f"{TermColors.CYAN}‚Üë Dropout adjusted: {current_rate:.2f} ‚Üí {new_rate:.2f}{TermColors.ENDC}")
                        
                        self.regularization_changes += 1
                        self.overfitting_streak = 0  # Reset after adjustment
            
            # Detect underfitting (training and validation both low but close)
            elif gap < 0.03 and train_acc < 0.5 and epoch > 5:
                self.underfitting_streak += 1
                self.overfitting_streak = 0
                
                if self.underfitting_streak >= 3 and self.regularization_changes < self.max_reg_changes:
                    print(f"{TermColors.YELLOW}‚ö†Ô∏è Underfitting detected (acc: {train_acc:.2f}, gap: {gap:.2f}) - Decreasing regularization{TermColors.ENDC}")
                    
                    # Decrease dropout rates if possible
                    if self.dropout_layers:
                        for layer in self.dropout_layers:
                            current_rate = tf.keras.backend.get_value(layer.rate)
                            new_rate = max(current_rate - 0.05, 0.1)  # Don't go below 0.1
                            layer.rate = new_rate
                            print(f"{TermColors.CYAN}‚Üì Dropout adjusted: {current_rate:.2f} ‚Üí {new_rate:.2f}{TermColors.ENDC}")
                        
                        self.regularization_changes += 1
                        self.underfitting_streak = 0  # Reset after adjustment
            else:
                # Reset both streaks if neither condition is met
                self.overfitting_streak = 0
                self.underfitting_streak = 0

class AdaptiveClassWeightAdjuster(tf.keras.callbacks.Callback):
    """Dynamically adjust class weights based on per-class performance"""
    def __init__(self, X_val, y_val, class_names, update_frequency=5):
        super().__init__()
        self.X_val = X_val
        self.y_val = y_val
        self.class_names = class_names
        self.update_frequency = update_frequency
        self.adjustments_made = 0
        self.max_adjustments = 3
        self.class_weights = None
        
    def on_train_begin(self, logs=None):
        # Initialize with equal class weights
        num_classes = len(self.class_names)
        self.class_weights = {i: 1.0 for i in range(num_classes)}
        
    def on_epoch_end(self, epoch, logs=None):
        # Only update weights periodically to allow training to adapt
        if epoch % self.update_frequency != 0 or self.adjustments_made >= self.max_adjustments:
            return
            
        # Get predictions on validation set
        y_pred = self.model.predict(self.X_val)
        y_pred_classes = np.argmax(y_pred, axis=1)
        
        # Calculate per-class accuracy
        class_accuracy = {}
        for cls in range(len(self.class_names)):
            # Find samples for this class
            mask = self.y_val == cls
            if np.sum(mask) == 0:  # No examples of this class
                continue
                
            # Calculate accuracy for this class
            correct = (y_pred_classes[mask] == cls).sum()
            total = mask.sum()
            class_accuracy[cls] = correct / total if total > 0 else 0.0
        
        # Find problematic classes
        overall_acc = logs.get('val_accuracy', 0)
        problem_classes = []
        
        for cls, acc in class_accuracy.items():
            # Classes with accuracy significantly below average
            if acc < overall_acc * 0.7:  # 30% below average is problematic
                problem_classes.append((cls, acc))
        
        # Adjust weights if we have problematic classes
        if problem_classes:
            print(f"{TermColors.YELLOW}‚ö†Ô∏è Found {len(problem_classes)} underperforming classes{TermColors.ENDC}")
            
            # Sort by lowest accuracy first
            problem_classes.sort(key=lambda x: x[1])
            
            # Just show a few examples
            for cls, acc in problem_classes[:3]:
                print(f"  - Class {self.class_names[cls]}: {acc:.2%} accuracy (vs {overall_acc:.2%} overall)")
                
                # Increase weight for this class
                old_weight = self.class_weights.get(cls, 1.0)
                new_weight = old_weight * 1.5  # Increase by 50%
                self.class_weights[cls] = min(new_weight, 5.0)  # Cap at 5x
                
                print(f"{TermColors.CYAN}‚Üë Weight adjusted: {old_weight:.2f} ‚Üí {self.class_weights[cls]:.2f}{TermColors.ENDC}")
            
            # Apply new class weights to model 
            print(f"{TermColors.CYAN}‚Ñπ Updated class weights will affect future training{TermColors.ENDC}")
            self.adjustments_made += 1

def test_time_augmentation_predict(image_path, top_k=5):
    """Memory-efficient prediction using test-time augmentation"""
    def check_memory_limit():
        mem = psutil.virtual_memory()
        if mem.percent > 85:  # Emergency cutoff
            print(f"{TermColors.RED}üö® RAM usage too high ({mem.percent}%). Cannot proceed with prediction.{TermColors.ENDC}")
            return False
        return True
        
    if not check_memory_limit():
        return []
    
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"TTA PLANT IDENTIFICATION: {os.path.basename(image_path)}")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Load and preprocess image once
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMAGE_SIZE)
    img = tf.keras.preprocessing.image.img_to_array(img)
    img_processed = tf.keras.applications.efficientnet_v2.preprocess_input(img)
    
    # Define efficient augmentations for plants
    augmentations = [
        {"name": "original", "transform": lambda img: img},
        {"name": "horizontal_flip", "transform": lambda img: np.fliplr(img)},
        {"name": "rotation_10", "transform": lambda img: tf.keras.preprocessing.image.apply_affine_transform(img, theta=10)},
        {"name": "brightness_up", "transform": lambda img: np.clip(img * 1.1, 0, 255)}
    ]
    
    # Load feature extractor once
    print(f"{TermColors.CYAN}‚Ñπ Loading feature extractor{TermColors.ENDC}")
    with tf.device('/GPU:0'):
        from tensorflow.keras.applications import EfficientNetV2L
        feature_extractor = EfficientNetV2L(
            input_shape=(*IMAGE_SIZE, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        feature_extractor.trainable = False
    
    # Dictionary to store all class predictions
    all_predictions = {}
    aug_bar = tqdm(total=len(augmentations), desc="Processing augmentations", position=0)
    
    # Process each augmentation separately
    for aug in augmentations:
        # Apply augmentation
        aug_bar.set_description(f"Processing {aug['name']}")
        img_aug = aug["transform"](img_processed.copy())
        img_batch = np.expand_dims(img_aug, axis=0)
        
        # Extract features
        features = feature_extractor.predict(img_batch, verbose=0)
        
        # Find and load models
        model_files = glob.glob(os.path.join(MODEL_DIR, "chunk_*_model.keras"))
        
        # Process each model
        for model_file in model_files:
            # Reset TF session between models to free memory
            tf.keras.backend.clear_session()
            
            chunk_idx = int(os.path.basename(model_file).split("_")[1])
            metadata_file = os.path.join(MODEL_DIR, f"chunk_{chunk_idx}_metadata.json")
            
            if not os.path.exists(metadata_file):
                continue
                
            # Load model and metadata
            with open(metadata_file) as f:
                metadata = json.load(f)
            
            model = tf.keras.models.load_model(model_file, custom_objects={
                'sparse_top_k_accuracy': sparse_top_k_accuracy
            })
            
            # Get predictions
            preds = model.predict(features, verbose=0)[0]
            
            # Get top predictions for this model
            top_indices = np.argsort(preds)[-top_k*2:][::-1]  # Get more candidates for consistency
            
            for idx in top_indices:
                class_name = metadata['class_mapping'][str(idx)]
                confidence = float(preds[idx])
                
                # Store predictions by class name
                class_key = f"{class_name}_{chunk_idx}"
                if class_key not in all_predictions:
                    all_predictions[class_key] = {
                        "class_name": class_name,
                        "chunk_idx": chunk_idx,
                        "total_score": 0,
                        "count": 0
                    }
                
                all_predictions[class_key]["total_score"] += confidence
                all_predictions[class_key]["count"] += 1
            
            # Free memory
            del model, preds
            gc.collect()
        
        # Free memory
        del img_aug, img_batch, features
        gc.collect()
        aug_bar.update(1)
    
    aug_bar.close()
    
    # Clean up GPU memory
    del feature_extractor
    gc.collect()
    tf.keras.backend.clear_session()
    
    # Calculate average score for each class
    final_predictions = []
    for class_key, data in all_predictions.items():
        avg_confidence = data["total_score"] / data["count"] if data["count"] > 0 else 0
        final_predictions.append((data["class_name"], avg_confidence, data["chunk_idx"]))
    
    # Sort by confidence
    final_predictions.sort(key=lambda x: x[1], reverse=True)
    
    # Print results
    print(f"\n{TermColors.HEADER}TOP {top_k} PREDICTIONS (WITH TTA):{TermColors.ENDC}")
    for i, (class_name, confidence, chunk_idx) in enumerate(final_predictions[:top_k]):
        confidence_bar = "‚ñà" * int(confidence * 20)
        confidence_str = f"[{confidence_bar:<20}] {confidence:.4f}"
        print(f"{i+1}. {TermColors.BOLD}{class_name}{TermColors.ENDC} - {TermColors.CYAN}{confidence_str}{TermColors.ENDC} (Chunk {chunk_idx})")
    
    return final_predictions[:top_k]

def self_consistency_predict(image_path, top_k=5):
    """Memory-efficient prediction with self-consistency checking"""
    def check_memory_limit():
        mem = psutil.virtual_memory()
        if mem.percent > 85:  # Emergency cutoff
            print(f"{TermColors.RED}üö® RAM usage too high ({mem.percent}%). Cannot proceed with prediction.{TermColors.ENDC}")
            return False
        return True
        
    if not check_memory_limit():
        return []
    
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"SELF-CONSISTENCY PLANT IDENTIFICATION: {os.path.basename(image_path)}")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Generate multiple augmentations of the input image
    def generate_augmentations(img_path, num_aug=4):
        """Generate multiple augmentations with different parameters"""
        # Load image once
        img = tf.keras.preprocessing.image.load_img(img_path, target_size=IMAGE_SIZE)
        img = tf.keras.preprocessing.image.img_to_array(img)
        
        # Create augmentations
        augmentations = []
        
        # Original image
        img_orig = tf.keras.applications.efficientnet_v2.preprocess_input(img.copy())
        augmentations.append(img_orig)
        
        # Flip horizontal
        img_flip = np.fliplr(img.copy())
        img_flip = tf.keras.applications.efficientnet_v2.preprocess_input(img_flip)
        augmentations.append(img_flip)
        
        # Rotate +10 degrees
        img_rot1 = tf.keras.preprocessing.image.apply_affine_transform(img.copy(), theta=10)
        img_rot1 = tf.keras.applications.efficientnet_v2.preprocess_input(img_rot1)
        augmentations.append(img_rot1)
        
        # Rotate -10 degrees
        img_rot2 = tf.keras.preprocessing.image.apply_affine_transform(img.copy(), theta=-10)
        img_rot2 = tf.keras.applications.efficientnet_v2.preprocess_input(img_rot2)
        augmentations.append(img_rot2)
        
        return augmentations
    
    # Generate augmentations
    print(f"{TermColors.CYAN}‚Ñπ Generating image augmentations{TermColors.ENDC}")
    augmented_images = generate_augmentations(image_path)
    
    # Load feature extractor
    print(f"{TermColors.CYAN}‚Ñπ Loading feature extractor{TermColors.ENDC}")
    with tf.device('/GPU:0'):
        from tensorflow.keras.applications import EfficientNetV2L
        feature_extractor = EfficientNetV2L(
            input_shape=(*IMAGE_SIZE, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        feature_extractor.trainable = False
    
    # Track votes for each class
    class_votes = {}
    
    # Process each augmentation independently to minimize memory usage
    aug_bar = tqdm(total=len(augmented_images), desc="Processing augmentations", position=0)
    
    for aug_idx, aug_img in enumerate(augmented_images):
        # Extract features
        img_batch = np.expand_dims(aug_img, axis=0)
        features = feature_extractor.predict(img_batch, verbose=0)
        
        # Load models
        model_files = glob.glob(os.path.join(MODEL_DIR, "chunk_*_model.keras"))
        
        for model_file in model_files:
            # Clean memory between models
            tf.keras.backend.clear_session()
            
            chunk_idx = int(os.path.basename(model_file).split("_")[1])
            metadata_file = os.path.join(MODEL_DIR, f"chunk_{chunk_idx}_metadata.json")
            
            if not os.path.exists(metadata_file):
                continue
                
            # Load model and metadata
            with open(metadata_file) as f:
                metadata = json.load(f)
            
            model = tf.keras.models.load_model(model_file, custom_objects={
                'sparse_top_k_accuracy': sparse_top_k_accuracy
            })
            
            # Get predictions
            preds = model.predict(features, verbose=0)[0]
            
            # Get top predictions 
            top_indices = np.argsort(preds)[-top_k*2:][::-1]  # Get more candidates
            
            for rank, idx in enumerate(top_indices):
                class_name = metadata['class_mapping'][str(idx)]
                confidence = float(preds[idx])
                
                # Weight by both rank and confidence
                # Higher rank (lower number) = higher weight
                rank_weight = 1.0 / (rank + 1)
                # Also consider which augmentation (original gets higher weight)
                aug_weight = 1.0 if aug_idx == 0 else 0.8
                
                # Compute vote weight
                vote_weight = confidence * rank_weight * aug_weight
                
                # Add to votes
                if class_name not in class_votes:
                    class_votes[class_name] = {
                        "score": 0,
                        "chunk_idx": chunk_idx,
                        "mentions": 0,
                        "highest_conf": 0
                    }
                
                class_votes[class_name]["score"] += vote_weight
                class_votes[class_name]["mentions"] += 1
                class_votes[class_name]["highest_conf"] = max(
                    class_votes[class_name]["highest_conf"], confidence
                )
            
            # Clean up model
            del model
            gc.collect()
        
        # Clean up features
        del features, img_batch
        gc.collect()
        aug_bar.update(1)
    
    aug_bar.close()
    
    # Clean up GPU memory
    del feature_extractor, augmented_images
    gc.collect()
    tf.keras.backend.clear_session()
    
    # Calculate consistency score:
    # - High score if appears in multiple augmentations
    # - High score if ranks high consistently
    final_predictions = []
    for class_name, data in class_votes.items():
        # Combine score with number of mentions for consistency
        # This favors classes that appear consistently across augmentations
        consistency_score = data["score"] * (data["mentions"] / (len(augmented_images) * 2))
        
        # Boost score of items that appeared in all augmentations
        if data["mentions"] >= len(augmented_images):
            consistency_score *= 1.2
        
        final_predictions.append((class_name, consistency_score, data["chunk_idx"]))
    
    # Sort by consistency score
    final_predictions.sort(key=lambda x: x[1], reverse=True)
    
    # Print results
    print(f"\n{TermColors.HEADER}TOP {top_k} PREDICTIONS (SELF-CONSISTENCY):{TermColors.ENDC}")
    for i, (class_name, score, chunk_idx) in enumerate(final_predictions[:top_k]):
        # Normalize score for display
        normalized_score = min(score / 2.0, 1.0)  # Scale for display
        confidence_bar = "‚ñà" * int(normalized_score * 20)
        confidence_str = f"[{confidence_bar:<20}] {normalized_score:.4f}"
        print(f"{i+1}. {TermColors.BOLD}{class_name}{TermColors.ENDC} - {TermColors.CYAN}{confidence_str}{TermColors.ENDC} (Chunk {chunk_idx})")
    
    return final_predictions[:top_k]

def cross_model_fusion_predict(image_path, top_k=5):
    """Memory-efficient prediction using cross-model feature fusion"""
    def check_memory_limit():
        mem = psutil.virtual_memory()
        if mem.percent > 85:  # Emergency cutoff
            print(f"{TermColors.RED}üö® RAM usage too high ({mem.percent}%). Cannot proceed with prediction.{TermColors.ENDC}")
            return False
        return True
    
    if not check_memory_limit():
        return []
    
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"CROSS-MODEL FUSION PLANT IDENTIFICATION: {os.path.basename(image_path)}")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Load image once
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMAGE_SIZE)
    img = tf.keras.preprocessing.image.img_to_array(img)
    
    # Create two copies with different preprocessing for different models
    img_efficient = tf.keras.applications.efficientnet_v2.preprocess_input(img.copy())
    img_efficient_batch = np.expand_dims(img_efficient, axis=0)
    
    print(f"{TermColors.CYAN}‚Ñπ Extracting features using dual-model approach{TermColors.ENDC}")
    
    # First extract primary features
    with tf.device('/GPU:0'):
        # Primary model - EfficientNetV2L
        print(f"{TermColors.CYAN}‚Ñπ Loading primary feature extractor (EfficientNetV2L){TermColors.ENDC}")
        from tensorflow.keras.applications import EfficientNetV2L
        feature_extractor1 = EfficientNetV2L(
            input_shape=(*IMAGE_SIZE, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        feature_extractor1.trainable = False
        
        # Extract primary features
        primary_features = feature_extractor1.predict(img_efficient_batch, verbose=0)
        
        # Free GPU memory
        del feature_extractor1
        gc.collect()
        tf.keras.backend.clear_session()
    
    # Process models with primary features
    print(f"{TermColors.CYAN}‚Ñπ Processing models with primary feature extractor{TermColors.ENDC}")
    primary_predictions = {}
    
    # Get all models
    model_files = glob.glob(os.path.join(MODEL_DIR, "chunk_*_model.keras"))
    model_bar = tqdm(total=len(model_files), desc="Processing models (primary)", position=0)
    
    for model_file in model_files:
        # Clean memory before each model
        tf.keras.backend.clear_session()
        
        chunk_idx = int(os.path.basename(model_file).split("_")[1])
        metadata_file = os.path.join(MODEL_DIR, f"chunk_{chunk_idx}_metadata.json")
        
        if not os.path.exists(metadata_file):
            model_bar.update(1)
            continue
            
        # Load model and metadata
        with open(metadata_file) as f:
            metadata = json.load(f)
        
        model = tf.keras.models.load_model(model_file, custom_objects={
            'sparse_top_k_accuracy': sparse_top_k_accuracy
        })
        
        # Get predictions
        preds = model.predict(primary_features, verbose=0)[0]
        
        # Store top predictions
        top_indices = np.argsort(preds)[-top_k*3:][::-1]  # Get more candidates
        
        for rank, idx in enumerate(top_indices):
            class_name = metadata['class_mapping'][str(idx)]
            confidence = float(preds[idx])
            
            class_key = f"{class_name}_{chunk_idx}"
            if class_key not in primary_predictions:
                primary_predictions[class_key] = {
                    "class_name": class_name,
                    "chunk_idx": chunk_idx,
                    "primary_score": 0,
                    "primary_rank": float('inf')
                }
            
            # Store confidence and best rank
            primary_predictions[class_key]["primary_score"] = confidence
            primary_predictions[class_key]["primary_rank"] = min(
                primary_predictions[class_key]["primary_rank"], rank
            )
        
        # Free memory
        del model, preds
        gc.collect()
        model_bar.update(1)
    
    model_bar.close()
    
    # Free primary features to save memory
    del primary_features, img_efficient, img_efficient_batch
    gc.collect()
    
    # Second feature extraction - use DenseNet121 for diversity
    # Prepare image for second model
    img_dense = tf.keras.applications.densenet.preprocess_input(img.copy())
    img_dense_batch = np.expand_dims(img_dense, axis=0)
    
    # Extract secondary features
    with tf.device('/GPU:0'):
        print(f"{TermColors.CYAN}‚Ñπ Loading secondary feature extractor (DenseNet121){TermColors.ENDC}")
        from tensorflow.keras.applications import DenseNet121
        feature_extractor2 = DenseNet121(
            input_shape=(*IMAGE_SIZE, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        feature_extractor2.trainable = False
        
        # Extract secondary features
        secondary_features = feature_extractor2.predict(img_dense_batch, verbose=0)
        
        # Free GPU memory
        del feature_extractor2
        gc.collect()
        tf.keras.backend.clear_session()
    
    # Process models with secondary features
    print(f"{TermColors.CYAN}‚Ñπ Processing models with secondary feature extractor{TermColors.ENDC}")
    secondary_predictions = {}
    
    model_bar = tqdm(total=len(model_files), desc="Processing models (secondary)", position=0)
    
    for model_file in model_files:
        # Clean memory before each model
        tf.keras.backend.clear_session()
        
        chunk_idx = int(os.path.basename(model_file).split("_")[1])
        metadata_file = os.path.join(MODEL_DIR, f"chunk_{chunk_idx}_metadata.json")
        
        if not os.path.exists(metadata_file):
            model_bar.update(1)
            continue
            
        # Load model and metadata
        with open(metadata_file) as f:
            metadata = json.load(f)
        
        model = tf.keras.models.load_model(model_file, custom_objects={
            'sparse_top_k_accuracy': sparse_top_k_accuracy
        })
        
        # Get predictions - may need to reshape or adapt secondary features
        try:
            # Try to predict directly
            preds = model.predict(secondary_features, verbose=0)[0]
        except:
            # If shape mismatch, adapt the features
            # This is just a fallback in case the model expects different dimensions
            # It will reduce accuracy but prevent crashes
            model_bar.update(1)
            continue
        
        # Store top predictions
        top_indices = np.argsort(preds)[-top_k*2:][::-1]
        
        for rank, idx in enumerate(top_indices):
            class_name = metadata['class_mapping'][str(idx)]
            confidence = float(preds[idx])
            
            class_key = f"{class_name}_{chunk_idx}"
            if class_key not in secondary_predictions:
                secondary_predictions[class_key] = {
                    "class_name": class_name,
                    "chunk_idx": chunk_idx,
                    "secondary_score": 0,
                    "secondary_rank": float('inf')
                }
            
            # Store confidence and best rank
            secondary_predictions[class_key]["secondary_score"] = confidence
            secondary_predictions[class_key]["secondary_rank"] = min(
                secondary_predictions[class_key]["secondary_rank"], rank
            )
        
        # Free memory
        del model, preds
        gc.collect()
        model_bar.update(1)
    
    model_bar.close()
    
    # Free secondary features
    del secondary_features, img_dense, img_dense_batch, img
    gc.collect()
    
    # Fusion approach - combine predictions from both models
    print(f"{TermColors.CYAN}‚Ñπ Fusing predictions from both feature extractors{TermColors.ENDC}")
    fused_predictions = []
    
    # First add all primary predictions
    for class_key, data in primary_predictions.items():
        class_name = data["class_name"]
        chunk_idx = data["chunk_idx"]
        primary_score = data["primary_score"]
        primary_rank = data["primary_rank"]
        
        # Check if this class also appeared in secondary predictions
        secondary_score = 0
        secondary_rank = float('inf')
        if class_key in secondary_predictions:
            secondary_score = secondary_predictions[class_key]["secondary_score"]
            secondary_rank = secondary_predictions[class_key]["secondary_rank"]
            
        # Calculate fusion score:
        # 1. Weight primary model higher (0.6 vs 0.4)
        # 2. Boost classes that appear in both models
        # 3. Consider both score and rank
        
        # Base scores from each model
        p_score = primary_score * (1.0 / (primary_rank + 1))
        s_score = secondary_score * (1.0 / (secondary_rank + 1))
        
        # Higher weight to primary model (60% primary, 40% secondary)
        alpha = 0.6
        beta = 0.4
        
        # Calculate weighted score
        if secondary_score > 0:
            # Class appeared in both models - use weighted average
            fusion_score = (alpha * p_score) + (beta * s_score)
            # Bonus for appearing in both models
            fusion_score *= 1.2
        else:
            # Class only appeared in primary model
            fusion_score = p_score * alpha
        
        fused_predictions.append((class_name, fusion_score, chunk_idx))
    
    # Now add any secondary predictions that weren't in primary
    for class_key, data in secondary_predictions.items():
        if class_key not in primary_predictions:
            class_name = data["class_name"]
            chunk_idx = data["chunk_idx"]
            secondary_score = data["secondary_score"]
            secondary_rank = data["secondary_rank"]
            
            # Calculate score (weighted less since only from secondary model)
            s_score = secondary_score * (1.0 / (secondary_rank + 1)) * 0.4
            
            fused_predictions.append((class_name, s_score, chunk_idx))
    
    # Sort by fusion score
    fused_predictions.sort(key=lambda x: x[1], reverse=True)
    
    # Print results
    print(f"\n{TermColors.HEADER}TOP {top_k} PREDICTIONS (CROSS-MODEL FUSION):{TermColors.ENDC}")
    for i, (class_name, score, chunk_idx) in enumerate(fused_predictions[:top_k]):
        # Normalize score for display
        normalized_score = min(score, 1.0)  # Ensure score is between 0 and 1
        confidence_bar = "‚ñà" * int(normalized_score * 20)
        confidence_str = f"[{confidence_bar:<20}] {normalized_score:.4f}"
        print(f"{i+1}. {TermColors.BOLD}{class_name}{TermColors.ENDC} - {TermColors.CYAN}{confidence_str}{TermColors.ENDC} (Chunk {chunk_idx})")
    
    return fused_predictions[:top_k]

def train_chunk_model(features_file, chunk_idx, training_state=None):
    """Train a model on the extracted features"""
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"TRAINING MODEL FOR CHUNK {chunk_idx+1}")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Extract directory and verify files
    chunk_feature_dir = os.path.dirname(features_file)
    class_mapping_file = os.path.join(chunk_feature_dir, "class_mapping.json")
    
    if not os.path.exists(class_mapping_file):
        print(f"{TermColors.RED}‚ùå Class mapping file not found: {class_mapping_file}{TermColors.ENDC}")
        return None
    
    # Load class mapping
    with open(class_mapping_file) as f:
        class_mapping = json.load(f)
    
    num_classes = len(class_mapping)
    print(f"{TermColors.CYAN}‚Ñπ Found {num_classes} classes in this chunk{TermColors.ENDC}")
    
    try:
        # Load features and analyze
        features, labels = analyze_features(features_file)
        if features is None or labels is None:
            print(f"{TermColors.RED}‚ùå Failed to load features for chunk {chunk_idx}{TermColors.ENDC}")
            return
            
        # Further analyze plant-specific characteristics
        confusability = analyze_plant_features(features, labels)
        
        # Standardize features
        print(f"{TermColors.CYAN}‚Ñπ Standardizing features{TermColors.ENDC}")
        scaler = StandardScaler()
        features_scaled = scaler.fit_transform(features)
        
        # Split data
        X_train, X_val, y_train, y_val = train_test_split(
            features_scaled, labels, test_size=0.2, random_state=42, stratify=labels
        )
        
        print(f"{TermColors.GREEN}‚úÖ Data split: {X_train.shape[0]} training, {X_val.shape[0]} validation samples{TermColors.ENDC}")
        
        # Build model
        feature_dim = features.shape[1]
        print(f"{TermColors.CYAN}‚Ñπ Building model for {num_classes} classes with {feature_dim} input features{TermColors.ENDC}")
        
        model = build_model(feature_dim, num_classes)
        
        # Compute class weights if imbalanced
        class_weights = None
        if len(np.unique(y_train)) > 1:  # Only if we have multiple classes
            try:
                # Count samples per class
                unique_classes = np.unique(y_train)
                class_counts = {cls: np.sum(y_train == cls) for cls in unique_classes}
                
                # Check for imbalance
                max_count = max(class_counts.values())
                min_count = min(class_counts.values())
                
                if max_count / min_count > 2:  # Significant imbalance
                    print(f"{TermColors.CYAN}‚Ñπ Class imbalance detected (max/min ratio: {max_count/min_count:.1f}){TermColors.ENDC}")
                    
                    # Compute balanced weights
                    weights = compute_class_weight(class_weight='balanced', classes=unique_classes, y=y_train)
                    class_weights = {i: w for i, w in zip(unique_classes, weights)}
                    
                    # Cap extreme weights
                    for cls, weight in class_weights.items():
                        if weight > 5:
                            class_weights[cls] = 5.0  # Cap at 5x
                            
                    print(f"{TermColors.CYAN}‚Ñπ Using class weights to balance training{TermColors.ENDC}")
            except Exception as e:
                print(f"{TermColors.YELLOW}‚ö†Ô∏è Could not compute class weights: {e}{TermColors.ENDC}")
        
        # Setup callbacks
        callbacks = [
            # Checkpoints to save best model
            ModelCheckpoint(
                filepath=os.path.join(CHECKPOINT_DIR, f"chunk_{chunk_idx}_best.keras"),
                save_best_only=True,
                monitor='val_loss',
                mode='min',
                verbose=1
            ),
            
            # Early stopping to prevent overfitting
            EarlyStopping(
                monitor='val_loss',
                patience=5,
                restore_best_weights=True,
                verbose=1
            ),
            
            # Dynamic optimizer for automatic learning rate adjustments
            DynamicTrainingOptimizer(patience=3),
            
            # Adaptive regularization based on overfitting detection
            AdaptiveRegularization(model),
            
            # Display progress with custom metrics visualization
            MetricsDisplayCallback(
                total_epochs=EPOCHS,
                validation_data=(X_val, y_val),
                training_state=training_state
            )
        ]
        
        # Check if we're resuming training
        start_epoch = 0
        if training_state and training_state.current_chunk == chunk_idx:
            start_epoch = training_state.current_epoch
            print(f"{TermColors.CYAN}‚Ñπ Resuming training from epoch {start_epoch + 1}{TermColors.ENDC}")
        
        # Train the model
        print(f"{TermColors.CYAN}‚Ñπ Training model for up to {EPOCHS} epochs{TermColors.ENDC}")
        history = model.fit(
            X_train, y_train,
            validation_data=(X_val, y_val),
            epochs=EPOCHS,
            initial_epoch=start_epoch,
            batch_size=BATCH_SIZE,
            callbacks=callbacks,
            class_weight=class_weights,
            verbose=0  # We use our own progress display
        )
        
        # Evaluate on validation set
        val_loss, val_acc, val_top_k = model.evaluate(X_val, y_val, verbose=0)
        print(f"\n{TermColors.HEADER}FINAL VALIDATION METRICS:{TermColors.ENDC}")
        print(f"{TermColors.RED}Loss: {val_loss:.4f}{TermColors.ENDC}")
        print(f"{TermColors.GREEN}Accuracy: {val_acc:.4f} ({val_acc:.1%}){TermColors.ENDC}")
        print(f"{TermColors.GREEN}Top-{TOP_K} Accuracy: {val_top_k:.4f} ({val_top_k:.1%}){TermColors.ENDC}")
        
        # Save the model
        model_file = os.path.join(MODEL_DIR, f"chunk_{chunk_idx}_model.keras")
        model.save(model_file)
        
        # Save metadata
        metadata = {
            "chunk_idx": chunk_idx,
            "num_classes": num_classes,
            "feature_dim": feature_dim,
            "class_mapping": class_mapping,
            "performance": {
                "val_loss": float(val_loss),
                "val_accuracy": float(val_acc),
                "val_sparse_top_k_accuracy": float(val_top_k)
            },
            "training_samples": int(X_train.shape[0]),
            "validation_samples": int(X_val.shape[0]),
            "confusability": float(confusability),
            "created": datetime.now().isoformat()
        }
        
        with open(os.path.join(MODEL_DIR, f"chunk_{chunk_idx}_metadata.json"), "w") as f:
            json.dump(metadata, f, indent=2)
            
        print(f"{TermColors.GREEN}‚úÖ Model saved to {model_file}{TermColors.ENDC}")
        
        # Mark chunk as processed
        if training_state:
            training_state.mark_chunk_complete(chunk_idx)
        
        # Clean up to prevent memory leaks
        clean_memory()
        
        # Prune features to save disk space
        prune_features_rolling_window(chunk_idx)
        
        return model
        
    except Exception as e:
        print(f"{TermColors.RED}‚ùå Error training model: {e}{TermColors.ENDC}")
        traceback.print_exc()
        return None

def predict_with_chunked_models(image_path, top_k=5):
    """Make predictions using all the chunked models with visual progress"""
    def check_memory_limit():
        mem = psutil.virtual_memory()
        if mem.percent > 85:  # Emergency cutoff
            print(f"{TermColors.RED}üö® RAM usage too high ({mem.percent}%). Cannot proceed with prediction.{TermColors.ENDC}")
            return False
        return True
    
    # Add this line HERE, after the function definition
    if not check_memory_limit():
        return []
    
    print(f"{TermColors.HEADER}\n{'='*50}")
    print(f"PREDICTION FOR: {os.path.basename(image_path)}")
    print(f"{'='*50}{TermColors.ENDC}")
    
    # Load and preprocess image
    img = tf.keras.preprocessing.image.load_img(image_path, target_size=IMAGE_SIZE)
    img = tf.keras.preprocessing.image.img_to_array(img)
    img_processed = tf.keras.applications.efficientnet_v2.preprocess_input(img)
    img_batch = np.expand_dims(img_processed, axis=0)
    
    # Load feature extractor
    print(f"{TermColors.CYAN}‚Ñπ Loading feature extractor{TermColors.ENDC}")
    with tf.device('/GPU:0'):
        from tensorflow.keras.applications import EfficientNetV2L
        
        feature_extractor = EfficientNetV2L(
            input_shape=(*IMAGE_SIZE, 3),
            include_top=False,
            weights='imagenet',
            pooling='avg'
        )
        feature_extractor.trainable = False
    
    # Extract features
    features = feature_extractor.predict(img_batch, verbose=0)
    
    # Find all trained chunk models
    model_files = glob.glob(os.path.join(MODEL_DIR, "chunk_*_model.keras"))
    
    if not model_files:
        print(f"{TermColors.RED}‚ùå No trained models found in {MODEL_DIR}{TermColors.ENDC}")
        return []
    
    print(f"{TermColors.CYAN}‚Ñπ Found {len(model_files)} trained chunk models{TermColors.ENDC}")
    
    # Process each model and collect predictions
    all_predictions = []
    model_bar = tqdm(total=len(model_files), desc="Processing models", position=0)
    
    for model_file in model_files:
        # Extract chunk index
        chunk_idx = int(os.path.basename(model_file).split("_")[1])
        
        # Load metadata
        metadata_file = os.path.join(MODEL_DIR, f"chunk_{chunk_idx}_metadata.json")
        
        if not os.path.exists(metadata_file):
            model_bar.update(1)
            continue
        
        with open(metadata_file) as f:
            metadata = json.load(f)
        
        # Load model
        model = tf.keras.models.load_model(model_file, custom_objects={
            'sparse_top_k_accuracy': sparse_top_k_accuracy
        })
        
        # Get predictions
        preds = model.predict(features, verbose=0)[0]
        
        # Get top predictions for this chunk
        top_indices = np.argsort(preds)[-top_k:][::-1]
        chunk_predictions = []
        
        for idx in top_indices:
            class_name = metadata['class_mapping'][str(idx)]
            confidence = float(preds[idx])
            chunk_predictions.append((class_name, confidence, chunk_idx))
        
        # Add to overall predictions
        all_predictions.extend(chunk_predictions)
        
        # Clean up
        del model
        model_bar.update(1)
        
        # Clear session to release memory
        tf.keras.backend.clear_session()
    
    model_bar.close()
    
    # Free resources
    del feature_extractor
    gc.collect()
    tf.keras.backend.clear_session()
    
    # Sort by confidence
    all_predictions.sort(key=lambda x: x[1], reverse=True)
    
    # Print top predictions
    print(f"\n{TermColors.HEADER}TOP {top_k} PREDICTIONS:{TermColors.ENDC}")
    for i, (class_name, confidence, chunk_idx) in enumerate(all_predictions[:top_k]):
        confidence_bar = "‚ñà" * int(confidence * 20)
        confidence_str = f"[{confidence_bar:<20}] {confidence:.4f}"
        print(f"{i+1}. {TermColors.BOLD}{class_name}{TermColors.ENDC} - {TermColors.CYAN}{confidence_str}{TermColors.ENDC} (Chunk {chunk_idx})")
    
    return all_predictions[:top_k]

if __name__ == "__main__":
    try:
        # Define gpus before using it
        gpus = tf.config.experimental.list_physical_devices('GPU')
        
        # Print system info with enhanced formatting
        print(f"{TermColors.HEADER}\n{'='*50}")
        print(f"PLANT RECOGNITION MODEL - OPTIMIZED FOR RTX 3050")
        print(f"{'='*50}{TermColors.ENDC}")
        
        gpu_info = ""
        if gpus:
            gpu_info = "NVIDIA GPU"
        else:
            gpu_info = "CPU (No GPU detected)"
            
        # Start training with chunk management
        # This is where your main code would go
        
    except Exception as e:
        print(f"{TermColors.RED}‚ùå Fatal error: {e}{TermColors.ENDC}")
        traceback.print_exc()